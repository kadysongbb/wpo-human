{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_gridworld\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# DR TRPO related files\n",
    "from grid_train_helper import *\n",
    "from value import NNValueFunction\n",
    "from utils import Logger\n",
    "from grid_dr_policy import DRPolicyKL, DRPolicyWass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Move to Yellow Room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 7 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 8 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 9 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 10 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 11 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 12 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 13 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 14 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 15 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 16 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "    \n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.2\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate\n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate\n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO + online human interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 7 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 8 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 9 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 10 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 11 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 12 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 13 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 14 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 15 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo-online-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.2\n",
    "\n",
    "human_recommendation = dict([(0,2),(8,2),(16,2),(24,1),(32,0),(40,0),(48,0),(1,2),(9,2),(17,2),(25,1),(33,0),(41,0),(49,0),\\\n",
    "                            (26,1),(3,2),(11,2),(19,2),(27,1),(35,0),(43,0),(51,0),(4,2),(12,2),(20,2),(28,1),(36,0),(44,0),(52,0),(29,1)])\n",
    "        \n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate\n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate\n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        #--------------- Human in the loop --------------- #\n",
    "        if human_recommendation[observe] != action: \n",
    "            all_advantages[observe][action] -= 1\n",
    "        else:\n",
    "            all_advantages[observe][action] += 1\n",
    "        #------------------------------------------------- #\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO + offline human interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 7 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 8 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 9 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 10 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 11 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 12 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 13 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 14 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 15 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo-offline-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.2\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "        \n",
    "    # human modifies the advantage\n",
    "    # left red room\n",
    "    all_advantages[0][2] += 1\n",
    "    all_advantages[8][2] += 1\n",
    "    all_advantages[16][2] += 1\n",
    "    all_advantages[24][1] += 1\n",
    "    all_advantages[32][0] += 1\n",
    "    all_advantages[40][0] += 1\n",
    "    all_advantages[48][0] += 1\n",
    "        \n",
    "    all_advantages[1][2] += 1\n",
    "    all_advantages[9][2] += 1\n",
    "    all_advantages[17][2] += 1\n",
    "    all_advantages[25][1] += 1\n",
    "    all_advantages[33][0] += 1\n",
    "    all_advantages[41][0] += 1\n",
    "    all_advantages[49][0] += 1\n",
    "        \n",
    "        \n",
    "    # middle path \n",
    "    all_advantages[26][1] += 1\n",
    "        \n",
    "    # middle blue room\n",
    "    all_advantages[3][2] += 1\n",
    "    all_advantages[11][2] += 1\n",
    "    all_advantages[19][2] += 1\n",
    "    all_advantages[27][1] += 1\n",
    "    all_advantages[35][0] += 1\n",
    "    all_advantages[43][0] += 1\n",
    "    all_advantages[51][0] += 1\n",
    "        \n",
    "    all_advantages[4][2] += 1\n",
    "    all_advantages[12][2] += 1\n",
    "    all_advantages[20][2] += 1\n",
    "    all_advantages[28][1] += 1\n",
    "    all_advantages[36][0] += 1\n",
    "    all_advantages[44][0] += 1\n",
    "    all_advantages[52][0] += 1\n",
    "        \n",
    "    # middle path \n",
    "    all_advantages[29][1] += 1\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO completely by humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 2 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 3 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 4 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 5 return -51.0000003 discounted reward -9.9536163\n",
      "Episode 6 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 7 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 8 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 9 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 10 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 11 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 12 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 13 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 14 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 15 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 18 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 19 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 20 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 21 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 22 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 23 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 24 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 25 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 26 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 27 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 30 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 31 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 34 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 35 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 36 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 37 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 38 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 39 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 40 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 41 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 42 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 43 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 44 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 45 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 49 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 50 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 51 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 52 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 53 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 54 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 57 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 58 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 59 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 60 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 61 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 62 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 63 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 64 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 65 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 69 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 72 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 73 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 74 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 75 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 76 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 77 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 78 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 79 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 82 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 83 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 84 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 85 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 86 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 87 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 88 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 89 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 90 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 91 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 94 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 95 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 96 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 97 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 98 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 99 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 100 return 95.0000003 discounted reward 54.9539003\n"
     ]
    }
   ],
   "source": [
    "env_name = \"GridWorld-v0\"\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/GridWorld-odrpo-complete-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyKL(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 100\n",
    "batch_eps = 1\n",
    "max_steps = 50 # max steps per episode\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "\n",
    "human_recommendation = dict([(0,2),(8,2),(16,2),(24,1),(32,0),(40,0),(48,0),(1,2),(9,2),(17,2),(25,1),(33,0),(41,0),(49,0),\\\n",
    "                            (26,1),(3,2),(11,2),(19,2),(27,1),(35,0),(43,0),(51,0),(4,2),(12,2),(20,2),(28,1),(36,0),(44,0),(52,0),(29,1)])\n",
    "        \n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        #--------------- Human writes the advantage table --------------- #\n",
    "        if human_recommendation[observe] != action: \n",
    "            all_advantages[observe][action] = -1\n",
    "        else:\n",
    "            all_advantages[observe][action] = 1\n",
    "        #---------------------------------------------------------------- #\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1174.0000003 discounted reward 14.0651403\n",
      "Episode 2 return 1390.0000003 discounted reward 14.2740993\n",
      "Episode 3 return 1276.0000003 discounted reward 11.6945903\n",
      "Episode 4 return 1346.0000003 discounted reward 13.7001683\n",
      "Episode 5 return 1282.0000003 discounted reward 9.5815123\n",
      "Episode 6 return 1852.0000003 discounted reward 15.9635843\n",
      "Episode 7 return 1788.0000003 discounted reward 16.7413803\n",
      "Episode 8 return 1848.0000003 discounted reward 15.1362373\n",
      "Episode 9 return 1666.0000003 discounted reward 23.4010663\n",
      "Episode 10 return 1832.0000003 discounted reward 14.1694293\n",
      "Episode 11 return 2026.0000003 discounted reward 18.0635833\n",
      "Episode 12 return 1936.0000003 discounted reward 15.1619543\n",
      "Episode 13 return 2012.0000003 discounted reward 18.9144883\n",
      "Episode 14 return 2176.0000003 discounted reward 18.5112483\n",
      "Episode 15 return 1772.0000003 discounted reward 17.4293403\n",
      "Episode 16 return 2108.0000003 discounted reward 17.4750583\n",
      "Episode 17 return 1926.0000003 discounted reward 22.1862773\n",
      "Episode 18 return 2224.0000003 discounted reward 20.4103293\n",
      "Episode 19 return 2212.0000003 discounted reward 17.2377963\n",
      "Episode 20 return 2120.0000003 discounted reward 15.4266513\n",
      "Episode 21 return 2204.0000003 discounted reward 18.2585333\n",
      "Episode 22 return 2410.0000003 discounted reward 19.0467513\n",
      "Episode 23 return 2296.0000003 discounted reward 15.9176743\n",
      "Episode 24 return 2308.0000003 discounted reward 20.1854143\n",
      "Episode 25 return 2488.0000003 discounted reward 19.5714443\n",
      "Episode 26 return 2176.0000003 discounted reward 16.2402873\n",
      "Episode 27 return 2222.0000003 discounted reward 17.1834713\n",
      "Episode 28 return 2742.0000003 discounted reward 24.7158633\n",
      "Episode 29 return 3118.0000003 discounted reward 23.4536003\n",
      "Episode 30 return 3126.0000003 discounted reward 17.8748323\n",
      "Episode 31 return 3318.0000003 discounted reward 16.5888793\n",
      "Episode 32 return 3064.0000003 discounted reward 20.6615333\n",
      "Episode 33 return 2860.0000003 discounted reward 18.3089623\n",
      "Episode 34 return 2962.0000003 discounted reward 19.0864013\n",
      "Episode 35 return 2874.0000003 discounted reward 16.0786303\n",
      "Episode 36 return 2636.0000003 discounted reward 19.9920053\n",
      "Episode 37 return 2974.0000003 discounted reward 10.2747063\n",
      "Episode 38 return 2748.0000003 discounted reward 15.8552483\n",
      "Episode 39 return 3080.0000003 discounted reward 16.4029473\n",
      "Episode 40 return 3796.0000003 discounted reward 23.6150363\n",
      "Episode 41 return 3186.0000003 discounted reward 45.5420413\n",
      "Episode 42 return 2960.0000003 discounted reward 15.0685183\n",
      "Episode 43 return 2756.0000003 discounted reward 15.3848993\n",
      "Episode 44 return 2942.0000003 discounted reward 21.6410933\n",
      "Episode 45 return 3256.0000003 discounted reward 23.4455373\n",
      "Episode 46 return 2832.0000003 discounted reward 19.1758703\n",
      "Episode 47 return 3678.0000003 discounted reward 16.8890883\n",
      "Episode 48 return 2994.0000003 discounted reward 17.1260063\n",
      "Episode 49 return 2514.0000003 discounted reward 15.7572723\n",
      "Episode 50 return 3082.0000003 discounted reward 28.7290273\n",
      "Episode 51 return 3050.0000003 discounted reward 10.8783473\n",
      "Episode 52 return 3182.0000003 discounted reward 18.9318183\n",
      "Episode 53 return 2476.0000003 discounted reward 19.3460643\n",
      "Episode 54 return 3002.0000003 discounted reward 19.3468583\n",
      "Episode 55 return 2548.0000003 discounted reward 22.1488353\n",
      "Episode 56 return 2740.0000003 discounted reward 16.2204353\n",
      "Episode 57 return 3482.0000003 discounted reward 33.1247743\n",
      "Episode 58 return 3584.0000003 discounted reward 16.9170543\n",
      "Episode 59 return 2884.0000003 discounted reward 32.6009683\n",
      "Episode 60 return 3358.0000003 discounted reward 31.0988433\n",
      "Episode 61 return 2920.0000003 discounted reward 21.7500643\n",
      "Episode 62 return 2926.0000003 discounted reward 14.2654743\n",
      "Episode 63 return 3018.0000003 discounted reward 16.0647423\n",
      "Episode 64 return 2788.0000003 discounted reward 18.4156323\n",
      "Episode 65 return 3168.0000003 discounted reward 16.4684743\n",
      "Episode 66 return 3554.0000003 discounted reward 11.8935493\n",
      "Episode 67 return 2898.0000003 discounted reward 44.8539463\n",
      "Episode 68 return 2658.0000003 discounted reward 32.0744303\n",
      "Episode 69 return 3294.0000003 discounted reward 26.6462973\n",
      "Episode 70 return 3216.0000003 discounted reward 44.3701793\n",
      "Episode 71 return 3308.0000003 discounted reward 16.3821593\n",
      "Episode 72 return 3116.0000003 discounted reward 14.4475203\n",
      "Episode 73 return 2888.0000003 discounted reward 14.0053243\n",
      "Episode 74 return 2824.0000003 discounted reward 23.9898233\n",
      "Episode 75 return 3100.0000003 discounted reward 21.9182403\n",
      "Episode 76 return 2952.0000003 discounted reward 19.9743603\n",
      "Episode 77 return 3170.0000003 discounted reward 20.6747663\n",
      "Episode 78 return 3410.0000003 discounted reward 23.2709423\n",
      "Episode 79 return 3200.0000003 discounted reward 37.5938323\n",
      "Episode 80 return 3106.0000003 discounted reward 22.3632203\n",
      "Episode 81 return 3138.0000003 discounted reward 23.7757003\n",
      "Episode 82 return 2868.0000003 discounted reward 30.5415043\n",
      "Episode 83 return 3294.0000003 discounted reward 10.2852653\n",
      "Episode 84 return 3062.0000003 discounted reward 14.1536253\n",
      "Episode 85 return 3270.0000003 discounted reward 17.9998923\n",
      "Episode 86 return 3072.0000003 discounted reward 27.8143503\n",
      "Episode 87 return 2940.0000003 discounted reward 33.2340123\n",
      "Episode 88 return 2706.0000003 discounted reward 39.5342493\n",
      "Episode 89 return 2926.0000003 discounted reward 17.6519793\n",
      "Episode 90 return 2892.0000003 discounted reward 17.9791313\n",
      "Episode 91 return 3062.0000003 discounted reward 20.7236343\n",
      "Episode 92 return 2772.0000003 discounted reward 14.5697543\n",
      "Episode 93 return 3132.0000003 discounted reward 16.6560933\n",
      "Episode 94 return 3544.0000003 discounted reward 41.2152973\n",
      "Episode 95 return 3188.0000003 discounted reward 36.6144863\n",
      "Episode 96 return 2918.0000003 discounted reward 19.4675573\n",
      "Episode 97 return 2724.0000003 discounted reward 21.8219933\n",
      "Episode 98 return 3148.0000003 discounted reward 21.8314453\n",
      "Episode 99 return 3098.0000003 discounted reward 25.1340253\n",
      "Episode 100 return 3300.0000003 discounted reward 18.0154703\n",
      "Episode 101 return 2820.0000003 discounted reward 20.5831673\n",
      "Episode 102 return 3532.0000003 discounted reward 22.6377113\n",
      "Episode 103 return 3234.0000003 discounted reward 48.8776153\n",
      "Episode 104 return 3034.0000003 discounted reward 29.3800393\n",
      "Episode 105 return 2984.0000003 discounted reward 34.8171483\n",
      "Episode 106 return 2666.0000003 discounted reward 19.8134133\n",
      "Episode 107 return 3448.0000003 discounted reward 16.3096263\n",
      "Episode 108 return 2574.0000003 discounted reward 21.9809323\n",
      "Episode 109 return 3254.0000003 discounted reward 12.9017463\n",
      "Episode 110 return 3778.0000003 discounted reward 13.9732933\n",
      "Episode 111 return 2696.0000003 discounted reward 20.1835483\n",
      "Episode 112 return 3474.0000003 discounted reward 13.5633633\n",
      "Episode 113 return 3096.0000003 discounted reward 18.6971623\n",
      "Episode 114 return 2794.0000003 discounted reward 16.1201633\n",
      "Episode 115 return 3230.0000003 discounted reward 36.5943403\n",
      "Episode 116 return 2272.0000003 discounted reward 18.4284093\n",
      "Episode 117 return 2960.0000003 discounted reward 20.9905753\n",
      "Episode 118 return 3076.0000003 discounted reward 30.0612353\n",
      "Episode 119 return 2724.0000003 discounted reward 18.9056243\n",
      "Episode 120 return 2976.0000003 discounted reward 15.3942773\n",
      "Episode 121 return 3316.0000003 discounted reward 21.2760133\n",
      "Episode 122 return 2944.0000003 discounted reward 24.0182483\n",
      "Episode 123 return 3116.0000003 discounted reward 35.0120493\n",
      "Episode 124 return 2616.0000003 discounted reward 20.0695753\n",
      "Episode 125 return 2492.0000003 discounted reward 18.6392993\n",
      "Episode 126 return 2632.0000003 discounted reward 20.9186513\n",
      "Episode 127 return 2920.0000003 discounted reward 16.4746713\n",
      "Episode 128 return 3084.0000003 discounted reward 22.9395573\n",
      "Episode 129 return 3010.0000003 discounted reward 14.2965963\n",
      "Episode 130 return 3212.0000003 discounted reward 13.9871503\n",
      "Episode 131 return 2888.0000003 discounted reward 23.4640953\n",
      "Episode 132 return 3272.0000003 discounted reward 17.1491123\n",
      "Episode 133 return 2884.0000003 discounted reward 17.1719303\n",
      "Episode 134 return 2764.0000003 discounted reward 25.1347953\n",
      "Episode 135 return 3048.0000003 discounted reward 19.0363923\n",
      "Episode 136 return 2912.0000003 discounted reward 22.4339523\n",
      "Episode 137 return 2714.0000003 discounted reward 21.4550653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 3078.0000003 discounted reward 30.6741623\n",
      "Episode 139 return 3348.0000003 discounted reward 17.4507633\n",
      "Episode 140 return 2898.0000003 discounted reward 47.3585933\n",
      "Episode 141 return 3200.0000003 discounted reward 20.1274293\n",
      "Episode 142 return 3200.0000003 discounted reward 18.8372133\n",
      "Episode 143 return 3104.0000003 discounted reward 19.4762333\n",
      "Episode 144 return 2918.0000003 discounted reward 32.5015163\n",
      "Episode 145 return 2652.0000003 discounted reward 28.1397443\n",
      "Episode 146 return 3106.0000003 discounted reward 15.8942373\n",
      "Episode 147 return 2904.0000003 discounted reward 21.1143033\n",
      "Episode 148 return 3150.0000003 discounted reward 17.3923473\n",
      "Episode 149 return 3194.0000003 discounted reward 27.0967593\n",
      "Episode 150 return 3218.0000003 discounted reward 17.7627973\n",
      "Episode 151 return 2894.0000003 discounted reward 19.0300373\n",
      "Episode 152 return 2856.0000003 discounted reward 15.3206193\n",
      "Episode 153 return 3244.0000003 discounted reward 38.3822963\n",
      "Episode 154 return 2942.0000003 discounted reward 34.7396403\n",
      "Episode 155 return 2858.0000003 discounted reward 25.6267353\n",
      "Episode 156 return 3184.0000003 discounted reward 17.6927083\n",
      "Episode 157 return 2768.0000003 discounted reward 20.2378573\n",
      "Episode 158 return 3068.0000003 discounted reward 24.3921623\n",
      "Episode 159 return 3254.0000003 discounted reward 16.0220743\n",
      "Episode 160 return 2700.0000003 discounted reward 23.5672173\n",
      "Episode 161 return 3080.0000003 discounted reward 22.6879543\n",
      "Episode 162 return 3368.0000003 discounted reward 22.1252933\n",
      "Episode 163 return 2938.0000003 discounted reward 25.1144343\n",
      "Episode 164 return 2870.0000003 discounted reward 15.2878673\n",
      "Episode 165 return 3024.0000003 discounted reward 22.0249253\n",
      "Episode 166 return 2970.0000003 discounted reward 7.7700003\n",
      "Episode 167 return 3492.0000003 discounted reward 29.6334613\n",
      "Episode 168 return 3684.0000003 discounted reward 14.5268663\n",
      "Episode 169 return 2830.0000003 discounted reward 29.7378003\n",
      "Episode 170 return 2600.0000003 discounted reward 22.5034063\n",
      "Episode 171 return 3172.0000003 discounted reward 22.7782513\n",
      "Episode 172 return 2966.0000003 discounted reward 31.7207173\n",
      "Episode 173 return 3098.0000003 discounted reward 12.3641813\n",
      "Episode 174 return 3206.0000003 discounted reward 19.7252263\n",
      "Episode 175 return 3398.0000003 discounted reward 22.6420413\n",
      "Episode 176 return 2572.0000003 discounted reward 9.7514223\n",
      "Episode 177 return 3080.0000003 discounted reward 13.2110423\n",
      "Episode 178 return 3452.0000003 discounted reward 36.1075653\n",
      "Episode 179 return 3280.0000003 discounted reward 15.3292463\n",
      "Episode 180 return 2932.0000003 discounted reward 25.3711303\n",
      "Episode 181 return 3346.0000003 discounted reward 30.8838103\n",
      "Episode 182 return 3066.0000003 discounted reward 29.0954793\n",
      "Episode 183 return 3348.0000003 discounted reward 59.8476913\n",
      "Episode 184 return 3240.0000003 discounted reward 51.9197723\n",
      "Episode 185 return 3032.0000003 discounted reward 18.5745103\n",
      "Episode 186 return 3134.0000003 discounted reward 38.8891833\n",
      "Episode 187 return 3074.0000003 discounted reward 18.7175313\n",
      "Episode 188 return 3316.0000003 discounted reward 15.7609603\n",
      "Episode 189 return 2920.0000003 discounted reward 17.6537063\n",
      "Episode 190 return 2900.0000003 discounted reward 25.6317673\n",
      "Episode 191 return 3262.0000003 discounted reward 15.9813963\n",
      "Episode 192 return 2848.0000003 discounted reward 26.8515173\n",
      "Episode 193 return 2950.0000003 discounted reward 11.1900503\n",
      "Episode 194 return 2588.0000003 discounted reward 20.3406483\n",
      "Episode 195 return 2810.0000003 discounted reward 18.4792283\n",
      "Episode 196 return 3048.0000003 discounted reward 19.8692663\n",
      "Episode 197 return 3124.0000003 discounted reward 20.1927923\n",
      "Episode 198 return 2674.0000003 discounted reward 14.8301423\n",
      "Episode 199 return 2700.0000003 discounted reward 10.1241443\n",
      "Episode 200 return 3132.0000003 discounted reward 15.2144043\n",
      "[array([-0.54110072,  0.13104214]), array([ 0.27808481, -0.77596607]), array([ 0.34879072, -2.7048001 ]), array([-1.72043684, -3.12128661]), array([ 0.04108753, -6.45521586])]\n",
      "[array([0., 1.]), array([1., 0.]), array([1., 0.]), array([1., 0.]), array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.05\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))\n",
    "print(all_advantages)\n",
    "print(policy.get_policy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO + online human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1212.0000003 discounted reward 12.8603903\n",
      "Episode 2 return 1318.0000003 discounted reward 11.9965603\n",
      "Episode 3 return 1362.0000003 discounted reward 14.3577553\n",
      "Episode 4 return 1252.0000003 discounted reward 10.5205883\n",
      "Episode 5 return 1234.0000003 discounted reward 10.7337473\n",
      "Episode 6 return 3826.0000003 discounted reward 23.3161283\n",
      "Episode 7 return 3876.0000003 discounted reward 21.7598833\n",
      "Episode 8 return 3372.0000003 discounted reward 25.1596503\n",
      "Episode 9 return 3376.0000003 discounted reward 54.1895283\n",
      "Episode 10 return 3992.0000003 discounted reward 23.2416023\n",
      "Episode 11 return 3792.0000003 discounted reward 18.1045753\n",
      "Episode 12 return 4268.0000003 discounted reward 13.1236903\n",
      "Episode 13 return 3400.0000003 discounted reward 31.7882443\n",
      "Episode 14 return 3308.0000003 discounted reward 31.0397953\n",
      "Episode 15 return 4102.0000003 discounted reward 37.8649703\n",
      "Episode 16 return 3492.0000003 discounted reward 39.2364363\n",
      "Episode 17 return 3540.0000003 discounted reward 15.2875283\n",
      "Episode 18 return 3586.0000003 discounted reward 28.0289973\n",
      "Episode 19 return 4118.0000003 discounted reward 20.9598363\n",
      "Episode 20 return 3518.0000003 discounted reward 22.2784413\n",
      "Episode 21 return 3554.0000003 discounted reward 37.5690133\n",
      "Episode 22 return 3130.0000003 discounted reward 7.3275563\n",
      "Episode 23 return 3670.0000003 discounted reward 53.1828863\n",
      "Episode 24 return 3840.0000003 discounted reward 9.4483553\n",
      "Episode 25 return 4100.0000003 discounted reward 36.6099993\n",
      "Episode 26 return 4058.0000003 discounted reward 33.9223023\n",
      "Episode 27 return 3650.0000003 discounted reward 43.6593833\n",
      "Episode 28 return 4030.0000003 discounted reward 28.6068283\n",
      "Episode 29 return 3540.0000003 discounted reward 27.7821843\n",
      "Episode 30 return 3914.0000003 discounted reward 28.2063873\n",
      "Episode 31 return 4066.0000003 discounted reward 17.6157023\n",
      "Episode 32 return 3896.0000003 discounted reward 22.6385483\n",
      "Episode 33 return 4420.0000003 discounted reward 20.5511853\n",
      "Episode 34 return 3946.0000003 discounted reward 8.8345653\n",
      "Episode 35 return 3874.0000003 discounted reward 38.1267483\n",
      "Episode 36 return 3480.0000003 discounted reward 9.1002183\n",
      "Episode 37 return 3528.0000003 discounted reward 11.7390763\n",
      "Episode 38 return 3344.0000003 discounted reward 22.4993873\n",
      "Episode 39 return 3622.0000003 discounted reward 7.3529713\n",
      "Episode 40 return 3822.0000003 discounted reward 39.0015893\n",
      "Episode 41 return 3582.0000003 discounted reward 8.3859213\n",
      "Episode 42 return 3700.0000003 discounted reward 34.4247433\n",
      "Episode 43 return 3298.0000003 discounted reward 29.5562093\n",
      "Episode 44 return 3362.0000003 discounted reward 23.2534623\n",
      "Episode 45 return 3854.0000003 discounted reward 48.0840333\n",
      "Episode 46 return 3480.0000003 discounted reward 36.2845193\n",
      "Episode 47 return 3824.0000003 discounted reward 51.0423403\n",
      "Episode 48 return 3882.0000003 discounted reward 16.9743233\n",
      "Episode 49 return 3350.0000003 discounted reward 13.8690743\n",
      "Episode 50 return 3694.0000003 discounted reward 14.5912693\n",
      "Episode 51 return 3470.0000003 discounted reward 17.1070923\n",
      "Episode 52 return 3640.0000003 discounted reward 13.0104983\n",
      "Episode 53 return 4090.0000003 discounted reward 18.2696653\n",
      "Episode 54 return 3682.0000003 discounted reward 12.6032013\n",
      "Episode 55 return 3962.0000003 discounted reward 29.1989413\n",
      "Episode 56 return 3776.0000003 discounted reward 46.6361753\n",
      "Episode 57 return 4004.0000003 discounted reward 22.6430873\n",
      "Episode 58 return 3742.0000003 discounted reward 34.3708643\n",
      "Episode 59 return 3106.0000003 discounted reward 13.4551733\n",
      "Episode 60 return 3590.0000003 discounted reward 43.6370573\n",
      "Episode 61 return 3550.0000003 discounted reward 17.3810373\n",
      "Episode 62 return 3666.0000003 discounted reward 26.9986563\n",
      "Episode 63 return 3536.0000003 discounted reward 35.7808333\n",
      "Episode 64 return 3602.0000003 discounted reward 16.1880013\n",
      "Episode 65 return 3790.0000003 discounted reward 12.5084323\n",
      "Episode 66 return 3362.0000003 discounted reward 16.8185583\n",
      "Episode 67 return 3684.0000003 discounted reward 27.0790543\n",
      "Episode 68 return 3790.0000003 discounted reward 29.3260553\n",
      "Episode 69 return 3698.0000003 discounted reward 19.1223363\n",
      "Episode 70 return 3518.0000003 discounted reward 22.0700943\n",
      "Episode 71 return 3348.0000003 discounted reward 5.7769213\n",
      "Episode 72 return 4202.0000003 discounted reward 21.3158583\n",
      "Episode 73 return 3338.0000003 discounted reward 48.7727593\n",
      "Episode 74 return 3394.0000003 discounted reward 47.3524583\n",
      "Episode 75 return 3912.0000003 discounted reward 32.2292093\n",
      "Episode 76 return 3588.0000003 discounted reward 8.1041033\n",
      "Episode 77 return 3766.0000003 discounted reward 15.8423143\n",
      "Episode 78 return 3458.0000003 discounted reward 23.2493563\n",
      "Episode 79 return 3926.0000003 discounted reward 22.5059053\n",
      "Episode 80 return 3284.0000003 discounted reward 47.5698133\n",
      "Episode 81 return 3758.0000003 discounted reward 13.0078043\n",
      "Episode 82 return 3778.0000003 discounted reward 32.8576073\n",
      "Episode 83 return 4042.0000003 discounted reward 23.1983693\n",
      "Episode 84 return 3242.0000003 discounted reward 14.8536753\n",
      "Episode 85 return 3676.0000003 discounted reward 4.6508813\n",
      "Episode 86 return 3458.0000003 discounted reward 35.5060743\n",
      "Episode 87 return 3438.0000003 discounted reward 18.0780223\n",
      "Episode 88 return 3756.0000003 discounted reward 39.5212983\n",
      "Episode 89 return 3542.0000003 discounted reward 43.2560113\n",
      "Episode 90 return 3686.0000003 discounted reward 19.8803183\n",
      "Episode 91 return 3558.0000003 discounted reward 11.8998053\n",
      "Episode 92 return 3834.0000003 discounted reward 22.4123313\n",
      "Episode 93 return 3794.0000003 discounted reward 51.4009623\n",
      "Episode 94 return 3332.0000003 discounted reward 22.3617473\n",
      "Episode 95 return 3662.0000003 discounted reward 23.9344793\n",
      "Episode 96 return 2912.0000003 discounted reward 18.7616723\n",
      "Episode 97 return 3796.0000003 discounted reward 29.6544533\n",
      "Episode 98 return 3688.0000003 discounted reward 5.7055783\n",
      "Episode 99 return 3414.0000003 discounted reward 17.9757773\n",
      "Episode 100 return 3550.0000003 discounted reward 35.6027993\n",
      "Episode 101 return 3446.0000003 discounted reward 10.4240793\n",
      "Episode 102 return 3888.0000003 discounted reward 39.0420003\n",
      "Episode 103 return 3578.0000003 discounted reward 40.6712433\n",
      "Episode 104 return 3454.0000003 discounted reward 35.0924383\n",
      "Episode 105 return 3942.0000003 discounted reward 17.2382013\n",
      "Episode 106 return 4058.0000003 discounted reward 18.2007713\n",
      "Episode 107 return 4230.0000003 discounted reward 41.3658863\n",
      "Episode 108 return 3738.0000003 discounted reward 23.6340293\n",
      "Episode 109 return 3392.0000003 discounted reward 18.1596633\n",
      "Episode 110 return 3182.0000003 discounted reward 39.8303453\n",
      "Episode 111 return 3452.0000003 discounted reward 32.6087093\n",
      "Episode 112 return 3720.0000003 discounted reward 13.4360333\n",
      "Episode 113 return 3514.0000003 discounted reward 38.3300973\n",
      "Episode 114 return 4082.0000003 discounted reward 30.7867933\n",
      "Episode 115 return 4136.0000003 discounted reward 46.4590213\n",
      "Episode 116 return 3920.0000003 discounted reward 49.7306063\n",
      "Episode 117 return 3646.0000003 discounted reward 14.3654863\n",
      "Episode 118 return 3480.0000003 discounted reward 15.8812943\n",
      "Episode 119 return 3946.0000003 discounted reward 33.1354683\n",
      "Episode 120 return 3988.0000003 discounted reward 17.6924893\n",
      "Episode 121 return 4074.0000003 discounted reward 26.5391653\n",
      "Episode 122 return 3854.0000003 discounted reward 27.2191793\n",
      "Episode 123 return 3888.0000003 discounted reward 22.3731123\n",
      "Episode 124 return 3392.0000003 discounted reward 24.7127273\n",
      "Episode 125 return 3296.0000003 discounted reward 16.3529373\n",
      "Episode 126 return 3802.0000003 discounted reward 48.3292813\n",
      "Episode 127 return 3830.0000003 discounted reward 31.7098393\n",
      "Episode 128 return 3960.0000003 discounted reward 30.7394723\n",
      "Episode 129 return 3944.0000003 discounted reward 29.4773123\n",
      "Episode 130 return 3336.0000003 discounted reward 17.1924583\n",
      "Episode 131 return 3654.0000003 discounted reward 47.6828843\n",
      "Episode 132 return 4264.0000003 discounted reward 35.7302053\n",
      "Episode 133 return 3160.0000003 discounted reward 15.0568323\n",
      "Episode 134 return 3856.0000003 discounted reward 8.7764973\n",
      "Episode 135 return 3470.0000003 discounted reward 21.7520243\n",
      "Episode 136 return 3836.0000003 discounted reward 31.4901953\n",
      "Episode 137 return 3804.0000003 discounted reward 35.2535093\n",
      "Episode 138 return 3840.0000003 discounted reward 13.8596633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 139 return 3824.0000003 discounted reward 17.7559953\n",
      "Episode 140 return 3276.0000003 discounted reward 16.9213863\n",
      "Episode 141 return 3760.0000003 discounted reward 34.7076023\n",
      "Episode 142 return 3290.0000003 discounted reward 36.9568823\n",
      "Episode 143 return 3668.0000003 discounted reward 27.5550393\n",
      "Episode 144 return 3322.0000003 discounted reward 30.0297283\n",
      "Episode 145 return 3706.0000003 discounted reward 36.9556713\n",
      "Episode 146 return 3520.0000003 discounted reward 15.6516063\n",
      "Episode 147 return 3530.0000003 discounted reward 40.8245253\n",
      "Episode 148 return 3248.0000003 discounted reward 30.2846963\n",
      "Episode 149 return 4174.0000003 discounted reward 47.1490103\n",
      "Episode 150 return 3934.0000003 discounted reward 41.5141533\n",
      "Episode 151 return 3658.0000003 discounted reward 36.2740463\n",
      "Episode 152 return 3962.0000003 discounted reward 25.8577293\n",
      "Episode 153 return 4348.0000003 discounted reward 49.1279943\n",
      "Episode 154 return 3690.0000003 discounted reward 10.6732593\n",
      "Episode 155 return 3112.0000003 discounted reward 17.8215043\n",
      "Episode 156 return 3552.0000003 discounted reward 32.0950333\n",
      "Episode 157 return 3662.0000003 discounted reward 6.2533623\n",
      "Episode 158 return 4148.0000003 discounted reward 50.8306173\n",
      "Episode 159 return 3284.0000003 discounted reward 32.8734353\n",
      "Episode 160 return 3664.0000003 discounted reward 48.0739873\n",
      "Episode 161 return 3386.0000003 discounted reward 23.0374303\n",
      "Episode 162 return 3502.0000003 discounted reward 15.7869433\n",
      "Episode 163 return 3598.0000003 discounted reward 34.6361123\n",
      "Episode 164 return 3924.0000003 discounted reward 21.7107143\n",
      "Episode 165 return 3202.0000003 discounted reward 26.7845333\n",
      "Episode 166 return 3558.0000003 discounted reward 49.4794653\n",
      "Episode 167 return 3446.0000003 discounted reward 35.6161113\n",
      "Episode 168 return 3796.0000003 discounted reward 39.4511923\n",
      "Episode 169 return 3356.0000003 discounted reward 45.8733793\n",
      "Episode 170 return 4312.0000003 discounted reward 25.7333813\n",
      "Episode 171 return 3810.0000003 discounted reward 35.1429923\n",
      "Episode 172 return 3272.0000003 discounted reward 13.9718673\n",
      "Episode 173 return 4042.0000003 discounted reward 31.6887883\n",
      "Episode 174 return 3150.0000003 discounted reward 28.3797783\n",
      "Episode 175 return 3662.0000003 discounted reward 32.5007713\n",
      "Episode 176 return 3600.0000003 discounted reward 25.6224863\n",
      "Episode 177 return 3276.0000003 discounted reward 18.6851953\n",
      "Episode 178 return 3704.0000003 discounted reward 17.0344763\n",
      "Episode 179 return 3206.0000003 discounted reward 22.2961243\n",
      "Episode 180 return 3812.0000003 discounted reward 12.9163373\n",
      "Episode 181 return 3876.0000003 discounted reward 33.0473383\n",
      "Episode 182 return 3966.0000003 discounted reward 14.1292113\n",
      "Episode 183 return 3980.0000003 discounted reward 13.2822293\n",
      "Episode 184 return 4080.0000003 discounted reward 17.9363793\n",
      "Episode 185 return 3840.0000003 discounted reward 15.4000923\n",
      "Episode 186 return 3716.0000003 discounted reward 31.6538583\n",
      "Episode 187 return 3540.0000003 discounted reward 12.0682623\n",
      "Episode 188 return 3434.0000003 discounted reward 18.8039283\n",
      "Episode 189 return 3400.0000003 discounted reward 13.7363583\n",
      "Episode 190 return 4040.0000003 discounted reward 8.8653383\n",
      "Episode 191 return 3684.0000003 discounted reward 12.5834053\n",
      "Episode 192 return 3468.0000003 discounted reward 29.7018493\n",
      "Episode 193 return 4066.0000003 discounted reward 29.0146613\n",
      "Episode 194 return 3606.0000003 discounted reward 27.6893853\n",
      "Episode 195 return 3526.0000003 discounted reward 35.5285733\n",
      "Episode 196 return 3264.0000003 discounted reward 18.7328113\n",
      "Episode 197 return 3330.0000003 discounted reward 38.5467713\n",
      "Episode 198 return 3478.0000003 discounted reward 17.8562633\n",
      "Episode 199 return 4068.0000003 discounted reward 38.7365303\n",
      "Episode 200 return 3910.0000003 discounted reward 9.7083603\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo-online-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.05\n",
    "\n",
    "human_recommendation = dict([(0,0),(1,0),(2,0),(3,0),(4,0)])\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        #--------------- Human in the loop --------------- #\n",
    "        if human_recommendation[observe] != action: \n",
    "            all_advantages[observe][action] -= 0.1\n",
    "        else:\n",
    "            all_advantages[observe][action] += 0.1\n",
    "        #------------------------------------------------- #\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO + offline human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1190.0000003 discounted reward 11.4357993\n",
      "Episode 2 return 1466.0000003 discounted reward 13.0208193\n",
      "Episode 3 return 1322.0000003 discounted reward 8.5814073\n",
      "Episode 4 return 1260.0000003 discounted reward 9.3045713\n",
      "Episode 5 return 1394.0000003 discounted reward 11.8486923\n",
      "Episode 6 return 2194.0000003 discounted reward 16.5420083\n",
      "Episode 7 return 2138.0000003 discounted reward 16.0481603\n",
      "Episode 8 return 2032.0000003 discounted reward 13.4210633\n",
      "Episode 9 return 3170.0000003 discounted reward 21.3629753\n",
      "Episode 10 return 3208.0000003 discounted reward 37.8912963\n",
      "Episode 11 return 3214.0000003 discounted reward 21.7396103\n",
      "Episode 12 return 3010.0000003 discounted reward 22.0163173\n",
      "Episode 13 return 3126.0000003 discounted reward 21.6623123\n",
      "Episode 14 return 3412.0000003 discounted reward 16.8538013\n",
      "Episode 15 return 3846.0000003 discounted reward 19.0900683\n",
      "Episode 16 return 3646.0000003 discounted reward 23.5003203\n",
      "Episode 17 return 3582.0000003 discounted reward 42.6105903\n",
      "Episode 18 return 3532.0000003 discounted reward 10.5012883\n",
      "Episode 19 return 4118.0000003 discounted reward 51.3685633\n",
      "Episode 20 return 3542.0000003 discounted reward 20.2242273\n",
      "Episode 21 return 3994.0000003 discounted reward 36.2389373\n",
      "Episode 22 return 3376.0000003 discounted reward 11.2407743\n",
      "Episode 23 return 3314.0000003 discounted reward 27.8318733\n",
      "Episode 24 return 3486.0000003 discounted reward 37.0695793\n",
      "Episode 25 return 3790.0000003 discounted reward 11.4814723\n",
      "Episode 26 return 3686.0000003 discounted reward 23.4695093\n",
      "Episode 27 return 3702.0000003 discounted reward 21.8578543\n",
      "Episode 28 return 3868.0000003 discounted reward 36.8496653\n",
      "Episode 29 return 3798.0000003 discounted reward 21.4188813\n",
      "Episode 30 return 3490.0000003 discounted reward 34.5086293\n",
      "Episode 31 return 3934.0000003 discounted reward 12.8695713\n",
      "Episode 32 return 4086.0000003 discounted reward 26.4816203\n",
      "Episode 33 return 3860.0000003 discounted reward 49.3636773\n",
      "Episode 34 return 3598.0000003 discounted reward 35.0650253\n",
      "Episode 35 return 3190.0000003 discounted reward 20.1532243\n",
      "Episode 36 return 3878.0000003 discounted reward 22.5372023\n",
      "Episode 37 return 3720.0000003 discounted reward 17.5258293\n",
      "Episode 38 return 3242.0000003 discounted reward 11.5881123\n",
      "Episode 39 return 3292.0000003 discounted reward 18.9594383\n",
      "Episode 40 return 4034.0000003 discounted reward 15.7358733\n",
      "Episode 41 return 3812.0000003 discounted reward 13.6592363\n",
      "Episode 42 return 3670.0000003 discounted reward 13.7752863\n",
      "Episode 43 return 3934.0000003 discounted reward 6.9936083\n",
      "Episode 44 return 3708.0000003 discounted reward 24.5352423\n",
      "Episode 45 return 3400.0000003 discounted reward 9.9377253\n",
      "Episode 46 return 3486.0000003 discounted reward 25.3874623\n",
      "Episode 47 return 3672.0000003 discounted reward 14.9640353\n",
      "Episode 48 return 3270.0000003 discounted reward 22.0545633\n",
      "Episode 49 return 3436.0000003 discounted reward 32.4345323\n",
      "Episode 50 return 3862.0000003 discounted reward 6.6380913\n",
      "Episode 51 return 3938.0000003 discounted reward 9.5062673\n",
      "Episode 52 return 3636.0000003 discounted reward 23.2230553\n",
      "Episode 53 return 3984.0000003 discounted reward 59.9016333\n",
      "Episode 54 return 3182.0000003 discounted reward 24.4249633\n",
      "Episode 55 return 3790.0000003 discounted reward 34.2238443\n",
      "Episode 56 return 3288.0000003 discounted reward 19.2111223\n",
      "Episode 57 return 4450.0000003 discounted reward 15.5058963\n",
      "Episode 58 return 3532.0000003 discounted reward 31.0818933\n",
      "Episode 59 return 3704.0000003 discounted reward 21.2398053\n",
      "Episode 60 return 3912.0000003 discounted reward 18.8572593\n",
      "Episode 61 return 3478.0000003 discounted reward 23.5469903\n",
      "Episode 62 return 3624.0000003 discounted reward 36.5493403\n",
      "Episode 63 return 3928.0000003 discounted reward 40.5627233\n",
      "Episode 64 return 3516.0000003 discounted reward 23.6236453\n",
      "Episode 65 return 3744.0000003 discounted reward 22.5580373\n",
      "Episode 66 return 3546.0000003 discounted reward 11.5693903\n",
      "Episode 67 return 3566.0000003 discounted reward 23.5095693\n",
      "Episode 68 return 3660.0000003 discounted reward 14.7394803\n",
      "Episode 69 return 3528.0000003 discounted reward 12.9477913\n",
      "Episode 70 return 3952.0000003 discounted reward 30.1902943\n",
      "Episode 71 return 3336.0000003 discounted reward 14.8415593\n",
      "Episode 72 return 3998.0000003 discounted reward 10.1624123\n",
      "Episode 73 return 3570.0000003 discounted reward 15.9415053\n",
      "Episode 74 return 3568.0000003 discounted reward 28.6576543\n",
      "Episode 75 return 3310.0000003 discounted reward 31.5921403\n",
      "Episode 76 return 4060.0000003 discounted reward 35.6547263\n",
      "Episode 77 return 3706.0000003 discounted reward 29.0469823\n",
      "Episode 78 return 4120.0000003 discounted reward 27.4502663\n",
      "Episode 79 return 3502.0000003 discounted reward 13.4748993\n",
      "Episode 80 return 3154.0000003 discounted reward 47.4664523\n",
      "Episode 81 return 2886.0000003 discounted reward 20.0418003\n",
      "Episode 82 return 2882.0000003 discounted reward 15.5732513\n",
      "Episode 83 return 3260.0000003 discounted reward 16.7123093\n",
      "Episode 84 return 3094.0000003 discounted reward 25.6839013\n",
      "Episode 85 return 3032.0000003 discounted reward 38.0217703\n",
      "Episode 86 return 2772.0000003 discounted reward 17.1529523\n",
      "Episode 87 return 3038.0000003 discounted reward 32.6720163\n",
      "Episode 88 return 3080.0000003 discounted reward 15.9973413\n",
      "Episode 89 return 3356.0000003 discounted reward 16.6410803\n",
      "Episode 90 return 3644.0000003 discounted reward 34.4388663\n",
      "Episode 91 return 3842.0000003 discounted reward 10.7236803\n",
      "Episode 92 return 4030.0000003 discounted reward 42.6182873\n",
      "Episode 93 return 3850.0000003 discounted reward 29.9912423\n",
      "Episode 94 return 3618.0000003 discounted reward 22.4187673\n",
      "Episode 95 return 3420.0000003 discounted reward 31.4820023\n",
      "Episode 96 return 3954.0000003 discounted reward 49.5321383\n",
      "Episode 97 return 3958.0000003 discounted reward 27.7909423\n",
      "Episode 98 return 3578.0000003 discounted reward 35.3088433\n",
      "Episode 99 return 3132.0000003 discounted reward 15.5234423\n",
      "Episode 100 return 3396.0000003 discounted reward 34.8051503\n",
      "Episode 101 return 3504.0000003 discounted reward 27.6457173\n",
      "Episode 102 return 3656.0000003 discounted reward 15.2337543\n",
      "Episode 103 return 3232.0000003 discounted reward 28.9359223\n",
      "Episode 104 return 3364.0000003 discounted reward 37.1198633\n",
      "Episode 105 return 3494.0000003 discounted reward 49.0962513\n",
      "Episode 106 return 3874.0000003 discounted reward 12.7128193\n",
      "Episode 107 return 3920.0000003 discounted reward 39.9702143\n",
      "Episode 108 return 3696.0000003 discounted reward 11.2049303\n",
      "Episode 109 return 3900.0000003 discounted reward 28.6707653\n",
      "Episode 110 return 3456.0000003 discounted reward 25.9325923\n",
      "Episode 111 return 3422.0000003 discounted reward 27.0406593\n",
      "Episode 112 return 3632.0000003 discounted reward 24.6331693\n",
      "Episode 113 return 3602.0000003 discounted reward 29.0303353\n",
      "Episode 114 return 3548.0000003 discounted reward 42.5477373\n",
      "Episode 115 return 4034.0000003 discounted reward 29.4817983\n",
      "Episode 116 return 3532.0000003 discounted reward 34.1943953\n",
      "Episode 117 return 3862.0000003 discounted reward 11.3169093\n",
      "Episode 118 return 3468.0000003 discounted reward 30.5690623\n",
      "Episode 119 return 3760.0000003 discounted reward 11.0817233\n",
      "Episode 120 return 3368.0000003 discounted reward 27.5376773\n",
      "Episode 121 return 3298.0000003 discounted reward 17.7213863\n",
      "Episode 122 return 3460.0000003 discounted reward 13.6375793\n",
      "Episode 123 return 3996.0000003 discounted reward 12.8719023\n",
      "Episode 124 return 3728.0000003 discounted reward 57.9618303\n",
      "Episode 125 return 3370.0000003 discounted reward 13.0040163\n",
      "Episode 126 return 4112.0000003 discounted reward 34.8067023\n",
      "Episode 127 return 3832.0000003 discounted reward 24.8414943\n",
      "Episode 128 return 3522.0000003 discounted reward 16.9732133\n",
      "Episode 129 return 3518.0000003 discounted reward 21.3624913\n",
      "Episode 130 return 3720.0000003 discounted reward 25.7501833\n",
      "Episode 131 return 3490.0000003 discounted reward 16.0055043\n",
      "Episode 132 return 3662.0000003 discounted reward 27.0541073\n",
      "Episode 133 return 3796.0000003 discounted reward 18.2608523\n",
      "Episode 134 return 3362.0000003 discounted reward 19.9754763\n",
      "Episode 135 return 3756.0000003 discounted reward 21.4170703\n",
      "Episode 136 return 3856.0000003 discounted reward 25.8627643\n",
      "Episode 137 return 3596.0000003 discounted reward 6.7849213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 3374.0000003 discounted reward 18.1566443\n",
      "Episode 139 return 3562.0000003 discounted reward 62.8372213\n",
      "Episode 140 return 3384.0000003 discounted reward 29.4159933\n",
      "Episode 141 return 3634.0000003 discounted reward 24.2437293\n",
      "Episode 142 return 3884.0000003 discounted reward 21.0375873\n",
      "Episode 143 return 3668.0000003 discounted reward 14.6371293\n",
      "Episode 144 return 3598.0000003 discounted reward 28.8574253\n",
      "Episode 145 return 3246.0000003 discounted reward 36.7610593\n",
      "Episode 146 return 3884.0000003 discounted reward 41.7773043\n",
      "Episode 147 return 3460.0000003 discounted reward 20.3706863\n",
      "Episode 148 return 3460.0000003 discounted reward 22.0905703\n",
      "Episode 149 return 3108.0000003 discounted reward 41.3440603\n",
      "Episode 150 return 3532.0000003 discounted reward 28.9042753\n",
      "Episode 151 return 3224.0000003 discounted reward 26.5687573\n",
      "Episode 152 return 3578.0000003 discounted reward 12.9340383\n",
      "Episode 153 return 3780.0000003 discounted reward 10.0720233\n",
      "Episode 154 return 3522.0000003 discounted reward 24.7446143\n",
      "Episode 155 return 4238.0000003 discounted reward 16.2418233\n",
      "Episode 156 return 3520.0000003 discounted reward 9.9991323\n",
      "Episode 157 return 3370.0000003 discounted reward 9.4882723\n",
      "Episode 158 return 3780.0000003 discounted reward 30.4308913\n",
      "Episode 159 return 3706.0000003 discounted reward 34.9186563\n",
      "Episode 160 return 3400.0000003 discounted reward 14.5406933\n",
      "Episode 161 return 3356.0000003 discounted reward 18.7944613\n",
      "Episode 162 return 3876.0000003 discounted reward 38.0343633\n",
      "Episode 163 return 3808.0000003 discounted reward 37.5871893\n",
      "Episode 164 return 4106.0000003 discounted reward 9.7911343\n",
      "Episode 165 return 3338.0000003 discounted reward 21.9545993\n",
      "Episode 166 return 3590.0000003 discounted reward 21.8662383\n",
      "Episode 167 return 3610.0000003 discounted reward 17.5854203\n",
      "Episode 168 return 3530.0000003 discounted reward 26.5223593\n",
      "Episode 169 return 3712.0000003 discounted reward 31.9254963\n",
      "Episode 170 return 4098.0000003 discounted reward 46.3321283\n",
      "Episode 171 return 3658.0000003 discounted reward 20.3864513\n",
      "Episode 172 return 3452.0000003 discounted reward 35.7537563\n",
      "Episode 173 return 4070.0000003 discounted reward 38.5614253\n",
      "Episode 174 return 4006.0000003 discounted reward 34.8444473\n",
      "Episode 175 return 3652.0000003 discounted reward 18.5171963\n",
      "Episode 176 return 3512.0000003 discounted reward 34.5030123\n",
      "Episode 177 return 3824.0000003 discounted reward 25.7569383\n",
      "Episode 178 return 3728.0000003 discounted reward 7.9330223\n",
      "Episode 179 return 3664.0000003 discounted reward 24.7801943\n",
      "Episode 180 return 3822.0000003 discounted reward 33.7767963\n",
      "Episode 181 return 3542.0000003 discounted reward 32.8995353\n",
      "Episode 182 return 3666.0000003 discounted reward 8.3550423\n",
      "Episode 183 return 3838.0000003 discounted reward 26.1927803\n",
      "Episode 184 return 3938.0000003 discounted reward 18.1176253\n",
      "Episode 185 return 3874.0000003 discounted reward 16.7403453\n",
      "Episode 186 return 3392.0000003 discounted reward 23.8415633\n",
      "Episode 187 return 3570.0000003 discounted reward 19.1573193\n",
      "Episode 188 return 3856.0000003 discounted reward 49.6393983\n",
      "Episode 189 return 4044.0000003 discounted reward 40.0932183\n",
      "Episode 190 return 3406.0000003 discounted reward 16.7956163\n",
      "Episode 191 return 3768.0000003 discounted reward 47.6017503\n",
      "Episode 192 return 3340.0000003 discounted reward 9.3951953\n",
      "Episode 193 return 3662.0000003 discounted reward 25.2857323\n",
      "Episode 194 return 3458.0000003 discounted reward 13.6116243\n",
      "Episode 195 return 3956.0000003 discounted reward 57.4337693\n",
      "Episode 196 return 3320.0000003 discounted reward 38.1451843\n",
      "Episode 197 return 3806.0000003 discounted reward 52.7846533\n",
      "Episode 198 return 3956.0000003 discounted reward 37.2193883\n",
      "Episode 199 return 3646.0000003 discounted reward 34.7175803\n",
      "Episode 200 return 3884.0000003 discounted reward 41.5563903\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo-offline-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "all_values = np.zeros(sta_num)\n",
    "learning_rate = 0.05\n",
    "\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        value_observe = all_values[observe]\n",
    "        value_next_observe = all_values[next_observe]\n",
    "        # update advantage\n",
    "        all_advantages[observe][action] = all_advantages[observe][action]*(1-learning_rate) + (reward + gamma*value_next_observe - value_observe)*learning_rate \n",
    "        # update value\n",
    "        all_values[observe] = all_values[observe]*(1-learning_rate) + (reward + gamma*value_next_observe)*learning_rate \n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "        \n",
    "    # human modifies the advantage\n",
    "    all_advantages[0][0] += 0.1\n",
    "    all_advantages[1][0] += 0.1\n",
    "    all_advantages[2][0] += 0.1\n",
    "    all_advantages[3][0] += 0.1\n",
    "    all_advantages[4][0] += 0.1\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODRPO completely by humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 return 1174.0000003 discounted reward 12.3564113\n",
      "Episode 2 return 1318.0000003 discounted reward 9.3407113\n",
      "Episode 3 return 1302.0000003 discounted reward 9.6858933\n",
      "Episode 4 return 1374.0000003 discounted reward 10.7497673\n",
      "Episode 5 return 1318.0000003 discounted reward 12.4484383\n",
      "Episode 6 return 4000.0000003 discounted reward 15.8747443\n",
      "Episode 7 return 3512.0000003 discounted reward 35.2320963\n",
      "Episode 8 return 3488.0000003 discounted reward 7.1453843\n",
      "Episode 9 return 3594.0000003 discounted reward 34.0022393\n",
      "Episode 10 return 3544.0000003 discounted reward 25.5213083\n",
      "Episode 11 return 3832.0000003 discounted reward 44.2063843\n",
      "Episode 12 return 3734.0000003 discounted reward 10.3228143\n",
      "Episode 13 return 3452.0000003 discounted reward 15.8702733\n",
      "Episode 14 return 3658.0000003 discounted reward 20.4800013\n",
      "Episode 15 return 3774.0000003 discounted reward 26.5611483\n",
      "Episode 16 return 3622.0000003 discounted reward 20.5375033\n",
      "Episode 17 return 3590.0000003 discounted reward 11.9679063\n",
      "Episode 18 return 3282.0000003 discounted reward 9.1354913\n",
      "Episode 19 return 3394.0000003 discounted reward 45.4784463\n",
      "Episode 20 return 3672.0000003 discounted reward 57.8497273\n",
      "Episode 21 return 3736.0000003 discounted reward 20.4858713\n",
      "Episode 22 return 3704.0000003 discounted reward 20.4275383\n",
      "Episode 23 return 3638.0000003 discounted reward 25.2039463\n",
      "Episode 24 return 3922.0000003 discounted reward 26.6309633\n",
      "Episode 25 return 3774.0000003 discounted reward 13.1244013\n",
      "Episode 26 return 3628.0000003 discounted reward 13.0024533\n",
      "Episode 27 return 3452.0000003 discounted reward 23.7918143\n",
      "Episode 28 return 3602.0000003 discounted reward 11.4127183\n",
      "Episode 29 return 3742.0000003 discounted reward 25.3992743\n",
      "Episode 30 return 3706.0000003 discounted reward 16.8763173\n",
      "Episode 31 return 3328.0000003 discounted reward 27.7212183\n",
      "Episode 32 return 3790.0000003 discounted reward 22.0435753\n",
      "Episode 33 return 3910.0000003 discounted reward 10.5133393\n",
      "Episode 34 return 3328.0000003 discounted reward 9.2851963\n",
      "Episode 35 return 4088.0000003 discounted reward 21.1926483\n",
      "Episode 36 return 3966.0000003 discounted reward 10.2329373\n",
      "Episode 37 return 3806.0000003 discounted reward 21.2122913\n",
      "Episode 38 return 3522.0000003 discounted reward 14.0835483\n",
      "Episode 39 return 3250.0000003 discounted reward 18.7260593\n",
      "Episode 40 return 3718.0000003 discounted reward 12.2280843\n",
      "Episode 41 return 3766.0000003 discounted reward 37.4952093\n",
      "Episode 42 return 3522.0000003 discounted reward 19.6641333\n",
      "Episode 43 return 3714.0000003 discounted reward 16.8158163\n",
      "Episode 44 return 3568.0000003 discounted reward 16.0432153\n",
      "Episode 45 return 3912.0000003 discounted reward 7.1034363\n",
      "Episode 46 return 3478.0000003 discounted reward 25.3578183\n",
      "Episode 47 return 4038.0000003 discounted reward 60.7660013\n",
      "Episode 48 return 3572.0000003 discounted reward 28.3491473\n",
      "Episode 49 return 3492.0000003 discounted reward 14.7115343\n",
      "Episode 50 return 3334.0000003 discounted reward 17.0490033\n",
      "Episode 51 return 3496.0000003 discounted reward 13.2864773\n",
      "Episode 52 return 3638.0000003 discounted reward 37.9651723\n",
      "Episode 53 return 3888.0000003 discounted reward 41.6426093\n",
      "Episode 54 return 3894.0000003 discounted reward 37.6122923\n",
      "Episode 55 return 3034.0000003 discounted reward 17.7891833\n",
      "Episode 56 return 4016.0000003 discounted reward 16.9078103\n",
      "Episode 57 return 3400.0000003 discounted reward 28.3967153\n",
      "Episode 58 return 4000.0000003 discounted reward 13.6989203\n",
      "Episode 59 return 3802.0000003 discounted reward 23.2497533\n",
      "Episode 60 return 3344.0000003 discounted reward 23.2807263\n",
      "Episode 61 return 3820.0000003 discounted reward 44.4865203\n",
      "Episode 62 return 3778.0000003 discounted reward 12.5493733\n",
      "Episode 63 return 3092.0000003 discounted reward 21.7965873\n",
      "Episode 64 return 3724.0000003 discounted reward 48.8656213\n",
      "Episode 65 return 3670.0000003 discounted reward 28.2431603\n",
      "Episode 66 return 3896.0000003 discounted reward 17.9376933\n",
      "Episode 67 return 4162.0000003 discounted reward 36.9888553\n",
      "Episode 68 return 3508.0000003 discounted reward 32.9861163\n",
      "Episode 69 return 3728.0000003 discounted reward 14.1117503\n",
      "Episode 70 return 3848.0000003 discounted reward 25.0862463\n",
      "Episode 71 return 3958.0000003 discounted reward 8.0472223\n",
      "Episode 72 return 3502.0000003 discounted reward 33.6215913\n",
      "Episode 73 return 3540.0000003 discounted reward 18.2243693\n",
      "Episode 74 return 3524.0000003 discounted reward 31.3289193\n",
      "Episode 75 return 3636.0000003 discounted reward 24.1718873\n",
      "Episode 76 return 3686.0000003 discounted reward 13.6953043\n",
      "Episode 77 return 3528.0000003 discounted reward 32.6302713\n",
      "Episode 78 return 3800.0000003 discounted reward 32.3108363\n",
      "Episode 79 return 3680.0000003 discounted reward 10.0521753\n",
      "Episode 80 return 3500.0000003 discounted reward 31.5639463\n",
      "Episode 81 return 3924.0000003 discounted reward 19.6744843\n",
      "Episode 82 return 3480.0000003 discounted reward 25.1638073\n",
      "Episode 83 return 3720.0000003 discounted reward 16.1038403\n",
      "Episode 84 return 3550.0000003 discounted reward 25.0407153\n",
      "Episode 85 return 3680.0000003 discounted reward 18.1166843\n",
      "Episode 86 return 3894.0000003 discounted reward 19.6195023\n",
      "Episode 87 return 3586.0000003 discounted reward 15.1135283\n",
      "Episode 88 return 3394.0000003 discounted reward 36.8268303\n",
      "Episode 89 return 3792.0000003 discounted reward 50.2167813\n",
      "Episode 90 return 3148.0000003 discounted reward 13.7924503\n",
      "Episode 91 return 3596.0000003 discounted reward 13.0049073\n",
      "Episode 92 return 3704.0000003 discounted reward 13.3021403\n",
      "Episode 93 return 3768.0000003 discounted reward 23.6762583\n",
      "Episode 94 return 3112.0000003 discounted reward 25.5982323\n",
      "Episode 95 return 3374.0000003 discounted reward 16.3987343\n",
      "Episode 96 return 3560.0000003 discounted reward 24.5217673\n",
      "Episode 97 return 3340.0000003 discounted reward 37.7720613\n",
      "Episode 98 return 3696.0000003 discounted reward 18.2893373\n",
      "Episode 99 return 3536.0000003 discounted reward 11.3167293\n",
      "Episode 100 return 4186.0000003 discounted reward 62.4906723\n",
      "Episode 101 return 3926.0000003 discounted reward 19.8795123\n",
      "Episode 102 return 3416.0000003 discounted reward 14.2690813\n",
      "Episode 103 return 3822.0000003 discounted reward 16.1651393\n",
      "Episode 104 return 3692.0000003 discounted reward 41.4592683\n",
      "Episode 105 return 3484.0000003 discounted reward 33.5979513\n",
      "Episode 106 return 3732.0000003 discounted reward 27.4972123\n",
      "Episode 107 return 3278.0000003 discounted reward 22.0486143\n",
      "Episode 108 return 3576.0000003 discounted reward 23.6447903\n",
      "Episode 109 return 3958.0000003 discounted reward 23.8572903\n",
      "Episode 110 return 3614.0000003 discounted reward 19.1030103\n",
      "Episode 111 return 3878.0000003 discounted reward 14.2151723\n",
      "Episode 112 return 3446.0000003 discounted reward 15.9250453\n",
      "Episode 113 return 4164.0000003 discounted reward 24.5955383\n",
      "Episode 114 return 3664.0000003 discounted reward 59.3150603\n",
      "Episode 115 return 3586.0000003 discounted reward 35.1653853\n",
      "Episode 116 return 3606.0000003 discounted reward 51.8556933\n",
      "Episode 117 return 3724.0000003 discounted reward 9.5355553\n",
      "Episode 118 return 3754.0000003 discounted reward 18.0968293\n",
      "Episode 119 return 3516.0000003 discounted reward 7.5247863\n",
      "Episode 120 return 3606.0000003 discounted reward 24.0781663\n",
      "Episode 121 return 3462.0000003 discounted reward 48.5525823\n",
      "Episode 122 return 3182.0000003 discounted reward 15.0021833\n",
      "Episode 123 return 3540.0000003 discounted reward 46.1012643\n",
      "Episode 124 return 3940.0000003 discounted reward 31.7675403\n",
      "Episode 125 return 3668.0000003 discounted reward 23.2419983\n",
      "Episode 126 return 3902.0000003 discounted reward 30.8526533\n",
      "Episode 127 return 3766.0000003 discounted reward 32.9815983\n",
      "Episode 128 return 3638.0000003 discounted reward 20.9679693\n",
      "Episode 129 return 3642.0000003 discounted reward 24.7189913\n",
      "Episode 130 return 3876.0000003 discounted reward 34.8985893\n",
      "Episode 131 return 3966.0000003 discounted reward 36.3141243\n",
      "Episode 132 return 3614.0000003 discounted reward 49.5850043\n",
      "Episode 133 return 3258.0000003 discounted reward 16.1080383\n",
      "Episode 134 return 3524.0000003 discounted reward 12.1470523\n",
      "Episode 135 return 4046.0000003 discounted reward 17.9046763\n",
      "Episode 136 return 4006.0000003 discounted reward 13.6006703\n",
      "Episode 137 return 3666.0000003 discounted reward 15.6209393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 3800.0000003 discounted reward 37.0756603\n",
      "Episode 139 return 3850.0000003 discounted reward 16.5871643\n",
      "Episode 140 return 3862.0000003 discounted reward 42.4268363\n",
      "Episode 141 return 3658.0000003 discounted reward 28.1892513\n",
      "Episode 142 return 3432.0000003 discounted reward 28.2277193\n",
      "Episode 143 return 3574.0000003 discounted reward 30.4255743\n",
      "Episode 144 return 4192.0000003 discounted reward 28.2385793\n",
      "Episode 145 return 4102.0000003 discounted reward 9.1894113\n",
      "Episode 146 return 3976.0000003 discounted reward 17.6148213\n",
      "Episode 147 return 4130.0000003 discounted reward 38.9676013\n",
      "Episode 148 return 4358.0000003 discounted reward 48.1688823\n",
      "Episode 149 return 3102.0000003 discounted reward 21.8094103\n",
      "Episode 150 return 4380.0000003 discounted reward 19.2220083\n",
      "Episode 151 return 4020.0000003 discounted reward 27.1384263\n",
      "Episode 152 return 3814.0000003 discounted reward 32.7201143\n",
      "Episode 153 return 3820.0000003 discounted reward 30.2226743\n",
      "Episode 154 return 4208.0000003 discounted reward 17.7635103\n",
      "Episode 155 return 3922.0000003 discounted reward 6.4751563\n",
      "Episode 156 return 3574.0000003 discounted reward 34.6470713\n",
      "Episode 157 return 3890.0000003 discounted reward 14.7243613\n",
      "Episode 158 return 3148.0000003 discounted reward 9.4031273\n",
      "Episode 159 return 3604.0000003 discounted reward 23.4422543\n",
      "Episode 160 return 3696.0000003 discounted reward 30.8944083\n",
      "Episode 161 return 4004.0000003 discounted reward 19.0001973\n",
      "Episode 162 return 4124.0000003 discounted reward 13.1453853\n",
      "Episode 163 return 3788.0000003 discounted reward 47.4600043\n",
      "Episode 164 return 3408.0000003 discounted reward 16.3547333\n",
      "Episode 165 return 3946.0000003 discounted reward 8.5102433\n",
      "Episode 166 return 3190.0000003 discounted reward 13.0765703\n",
      "Episode 167 return 3900.0000003 discounted reward 45.9537883\n",
      "Episode 168 return 3426.0000003 discounted reward 21.2411523\n",
      "Episode 169 return 3360.0000003 discounted reward 13.0237453\n",
      "Episode 170 return 3936.0000003 discounted reward 9.7651123\n",
      "Episode 171 return 3906.0000003 discounted reward 24.3565673\n",
      "Episode 172 return 3812.0000003 discounted reward 12.9852793\n",
      "Episode 173 return 3642.0000003 discounted reward 42.2014393\n",
      "Episode 174 return 3456.0000003 discounted reward 24.4019453\n",
      "Episode 175 return 3642.0000003 discounted reward 23.1875063\n",
      "Episode 176 return 3432.0000003 discounted reward 36.0136053\n",
      "Episode 177 return 4032.0000003 discounted reward 29.3169353\n",
      "Episode 178 return 3330.0000003 discounted reward 21.6671123\n",
      "Episode 179 return 3666.0000003 discounted reward 14.7364213\n",
      "Episode 180 return 3286.0000003 discounted reward 24.0865243\n",
      "Episode 181 return 3674.0000003 discounted reward 19.9636083\n",
      "Episode 182 return 3432.0000003 discounted reward 19.4110613\n",
      "Episode 183 return 4050.0000003 discounted reward 50.6681133\n",
      "Episode 184 return 3482.0000003 discounted reward 34.1167413\n",
      "Episode 185 return 3860.0000003 discounted reward 15.4927093\n",
      "Episode 186 return 3566.0000003 discounted reward 24.5710123\n",
      "Episode 187 return 3254.0000003 discounted reward 13.6408473\n",
      "Episode 188 return 4222.0000003 discounted reward 58.6664563\n",
      "Episode 189 return 3802.0000003 discounted reward 8.2258683\n",
      "Episode 190 return 3950.0000003 discounted reward 8.1896523\n",
      "Episode 191 return 3770.0000003 discounted reward 16.1428543\n",
      "Episode 192 return 3600.0000003 discounted reward 26.9255963\n",
      "Episode 193 return 3092.0000003 discounted reward 18.6046083\n",
      "Episode 194 return 4612.0000003 discounted reward 45.8098623\n",
      "Episode 195 return 3752.0000003 discounted reward 31.9888803\n",
      "Episode 196 return 3622.0000003 discounted reward 25.1458693\n",
      "Episode 197 return 3256.0000003 discounted reward 10.0020343\n",
      "Episode 198 return 3668.0000003 discounted reward 28.6253233\n",
      "Episode 199 return 3750.0000003 discounted reward 8.6072163\n",
      "Episode 200 return 3554.0000003 discounted reward 22.2878913\n"
     ]
    }
   ],
   "source": [
    "env_name = 'NChain-v0'\n",
    "env = gym.make(env_name)\n",
    "file_name = \"log_files/NChain-odrpo-complete-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "start = time.time()\n",
    "\n",
    "sta_num = env.observation_space.n\n",
    "act_num = env.action_space.n\n",
    "policy = DRPolicyWass(sta_num, act_num)\n",
    "gamma = 0.9\n",
    "lam = 1\n",
    "total_eps = 200\n",
    "batch_eps = 1\n",
    "max_steps = 1000\n",
    "all_advantages = []\n",
    "for i in range(sta_num):\n",
    "    all_advantages.append(np.zeros(act_num))\n",
    "\n",
    "human_recommendation = dict([(0,0),(1,0),(2,0),(3,0),(4,0)])\n",
    "\n",
    "eps = 0\n",
    "while eps < total_eps:\n",
    "    steps = 0\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    discounted_reward = 0\n",
    "    done = False\n",
    "    while steps <= max_steps and not done: \n",
    "        observe, action, reward, next_observe, done = run_step(env, obs, policy)\n",
    "        # calculate total and discounted rewards\n",
    "        total_reward += reward\n",
    "        discounted_reward += (gamma**steps)*reward\n",
    "        #--------------- Human writes the advantage table --------------- #\n",
    "        if human_recommendation[observe] != action: \n",
    "            all_advantages[observe][action] = -1\n",
    "        else:\n",
    "            all_advantages[observe][action] = 1\n",
    "        #---------------------------------------------------------------- #\n",
    "        # update policy\n",
    "        if eps >= 5:\n",
    "            policy.update(all_advantages, env_name)\n",
    "        steps += 1\n",
    "        obs = next_observe\n",
    "    eps += 1\n",
    "    runtime = time.time() - start\n",
    "    with open(file_name, 'a') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\",\")\n",
    "        writer.writerow((str(total_reward), str(eps), str(runtime)))\n",
    "    print('Episode %d return %f3 discounted reward %f3' %(eps, total_reward, discounted_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
