{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "import csv\n",
    "import gym_gridworld\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Move to Yellow Room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (online) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 2 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 3 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 4 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 5 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 6 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 7 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 8 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 9 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 10 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 11 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 12 return 50.0000003 discounted reward -9.4330853\n",
      "Episode 13 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 14 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 15 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 16 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 17 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 18 return 66.0000003 discounted reward -6.9405883\n",
      "Episode 19 return 63.0000003 discounted reward -7.7696883\n",
      "Episode 20 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 21 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 22 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 23 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 24 return 75.0000003 discounted reward -2.1031223\n",
      "Episode 25 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 26 return 60.0000003 discounted reward -8.3741033\n",
      "Episode 27 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 28 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 29 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 30 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 31 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 32 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 33 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 34 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 35 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 36 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 37 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 38 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 39 return 62.0000003 discounted reward -7.9927203\n",
      "Episode 40 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 41 return 76.0000003 discounted reward -1.2256913\n",
      "Episode 42 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 43 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 44 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 45 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 46 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 47 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 48 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 49 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 50 return 71.0000003 discounted reward -4.8188583\n",
      "Episode 51 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 52 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 53 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 54 return 65.0000003 discounted reward -7.2465293\n",
      "Episode 55 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 56 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 57 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 58 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 59 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 60 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 61 return 55.0000003 discounted reward -9.0399243\n",
      "Episode 62 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 63 return 76.0000003 discounted reward -1.2256913\n",
      "Episode 64 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 65 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 66 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 67 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 68 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 69 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 70 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 71 return 71.0000003 discounted reward -4.8188583\n",
      "Episode 72 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 73 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 74 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 75 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 76 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 77 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 78 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 79 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 80 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 81 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 82 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 83 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 84 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 85 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 86 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 87 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 88 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 89 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 90 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 91 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 92 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 93 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 94 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 95 return 64.0000003 discounted reward -7.5218763\n",
      "Episode 96 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 97 return 69.0000003 discounted reward -5.8032753\n",
      "Episode 98 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 99 return 93.0000003 discounted reward 42.6126593\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (online) + online human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 2 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 3 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 4 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 5 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 6 return 70.0000003 discounted reward -5.3369733\n",
      "Episode 7 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 8 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 9 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 10 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 11 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 12 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 13 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 14 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 15 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 16 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 17 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 18 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 19 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 20 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 21 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 22 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 23 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 24 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 25 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 26 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 27 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 28 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 29 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 30 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 31 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 32 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 33 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 34 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 35 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 36 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 37 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 38 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 39 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 40 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 41 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 42 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 43 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 44 return 65.0000003 discounted reward -7.2465293\n",
      "Episode 45 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 46 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 47 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 48 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 49 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 50 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 51 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 52 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 53 return 68.0000003 discounted reward -6.2229483\n",
      "Episode 54 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 55 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 56 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 57 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 58 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 59 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 60 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 61 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 62 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 63 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 64 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 65 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 66 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 67 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 68 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 69 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 70 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 71 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 72 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 73 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 74 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 75 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 76 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 77 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 78 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 79 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 80 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 81 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 82 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 83 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 84 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 85 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 86 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 87 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 88 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 89 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 90 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 91 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 92 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 93 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 94 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 95 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 96 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 97 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 98 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 99 return 89.0000003 discounted reward 24.5191663\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning-online-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "human_recommendation = dict([(0,2),(8,2),(16,2),(24,1),(32,0),(40,0),(48,0),(1,2),(9,2),(17,2),(25,1),(33,0),(41,0),(49,0),\\\n",
    "                            (26,1),(3,2),(11,2),(19,2),(27,1),(35,0),(43,0),(51,0),(4,2),(12,2),(20,2),(28,1),(36,0),(44,0),(52,0),(29,1)])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            \n",
    "            #--------------- Human in the loop --------------- #\n",
    "            if human_recommendation[observation] != a: \n",
    "                Q[observation][a] -= 1\n",
    "            else:\n",
    "                Q[observation][a] += 1\n",
    "            #------------------------------------------------- #\n",
    "            \n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (online) + offline human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return -52.0000003 discounted reward -9.9582543\n",
      "Episode 1 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 2 return 76.0000003 discounted reward -1.2256913\n",
      "Episode 3 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 4 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 5 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 6 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 7 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 8 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 9 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 10 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 11 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 12 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 13 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 14 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 15 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 16 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 17 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 18 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 19 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 20 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 21 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 22 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 23 return 75.0000003 discounted reward -2.1031223\n",
      "Episode 24 return 77.0000003 discounted reward -0.2507683\n",
      "Episode 25 return 68.0000003 discounted reward -6.2229483\n",
      "Episode 26 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 27 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 28 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 29 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 30 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 31 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 32 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 33 return 75.0000003 discounted reward -2.1031223\n",
      "Episode 34 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 35 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 36 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 37 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 38 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 39 return 60.0000003 discounted reward -8.3741033\n",
      "Episode 40 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 41 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 42 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 43 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 44 return 80.0000003 discounted reward 3.3734323\n",
      "Episode 45 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 46 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 47 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 48 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 49 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 50 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 51 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 52 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 53 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 54 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 55 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 56 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 57 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 58 return 88.0000003 discounted reward 21.0672493\n",
      "Episode 59 return 78.0000003 discounted reward 0.8324803\n",
      "Episode 60 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 61 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 62 return 62.0000003 discounted reward -7.9927203\n",
      "Episode 63 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 64 return 87.0000003 discounted reward 17.9605243\n",
      "Episode 65 return 72.0000003 discounted reward -4.2431763\n",
      "Episode 66 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 67 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 68 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 69 return 91.0000003 discounted reward 32.6162543\n",
      "Episode 70 return 95.0000003 discounted reward 54.9539003\n",
      "Episode 71 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 72 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 73 return 83.0000003 discounted reward 8.3449003\n",
      "Episode 74 return 92.0000003 discounted reward 37.3513933\n",
      "Episode 75 return 76.0000003 discounted reward -1.2256913\n",
      "Episode 76 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 77 return 85.0000003 discounted reward 12.6480253\n",
      "Episode 78 return 68.0000003 discounted reward -6.2229483\n",
      "Episode 79 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 80 return 73.0000003 discounted reward -3.6035293\n",
      "Episode 81 return 84.0000003 discounted reward 10.3832223\n",
      "Episode 82 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 83 return 86.0000003 discounted reward 15.1644723\n",
      "Episode 84 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 85 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 86 return 75.0000003 discounted reward -2.1031223\n",
      "Episode 87 return 90.0000003 discounted reward 28.3546283\n",
      "Episode 88 return 81.0000003 discounted reward 4.8593693\n",
      "Episode 89 return 82.0000003 discounted reward 6.5104103\n",
      "Episode 90 return 89.0000003 discounted reward 24.5191663\n",
      "Episode 91 return 74.0000003 discounted reward -2.8928103\n",
      "Episode 92 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 93 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 94 return 79.0000003 discounted reward 2.0360893\n",
      "Episode 95 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 96 return 67.0000003 discounted reward -6.6006533\n",
      "Episode 97 return 94.0000003 discounted reward 48.4585103\n",
      "Episode 98 return 93.0000003 discounted reward 42.6126593\n",
      "Episode 99 return 87.0000003 discounted reward 17.9605243\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"GridWorld-v0\")\n",
    "file_name = \"log_files/GridWorld-q-learning-offline-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "    \n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 50):\n",
    "    Q = defaultdict(lambda: np.zeros(env.n_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.n_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "            \n",
    "        # human modifies the Q\n",
    "        # left red room\n",
    "        Q[0][2] += 1\n",
    "        Q[8][2] += 1\n",
    "        Q[16][2] += 1\n",
    "        Q[24][1] += 1\n",
    "        Q[32][0] += 1\n",
    "        Q[40][0] += 1\n",
    "        Q[48][0] += 1\n",
    "        \n",
    "        Q[1][2] += 1\n",
    "        Q[9][2] += 1\n",
    "        Q[17][2] += 1\n",
    "        Q[25][1] += 1\n",
    "        Q[33][0] += 1\n",
    "        Q[41][0] += 1\n",
    "        Q[49][0] += 1\n",
    "        \n",
    "        \n",
    "        # middle path \n",
    "        Q[26][1] += 1\n",
    "        \n",
    "        # middle blue room\n",
    "        Q[3][2] += 1\n",
    "        Q[11][2] += 1\n",
    "        Q[19][2] += 1\n",
    "        Q[27][1] += 1\n",
    "        Q[35][0] += 1\n",
    "        Q[43][0] += 1\n",
    "        Q[51][0] += 1\n",
    "        \n",
    "        Q[4][2] += 1\n",
    "        Q[12][2] += 1\n",
    "        Q[20][2] += 1\n",
    "        Q[28][1] += 1\n",
    "        Q[36][0] += 1\n",
    "        Q[44][0] += 1\n",
    "        Q[52][0] += 1\n",
    "        \n",
    "        # middle path \n",
    "        Q[29][1] += 1\n",
    "        \n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (online) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1450.0000003 discounted reward 17.0373573\n",
      "Episode 1 return 1704.0000003 discounted reward 11.6211963\n",
      "Episode 2 return 1860.0000003 discounted reward 14.5074633\n",
      "Episode 3 return 2046.0000003 discounted reward 22.2174263\n",
      "Episode 4 return 2054.0000003 discounted reward 13.5237953\n",
      "Episode 5 return 1906.0000003 discounted reward 7.9870883\n",
      "Episode 6 return 1738.0000003 discounted reward 27.2632553\n",
      "Episode 7 return 1802.0000003 discounted reward 12.9249403\n",
      "Episode 8 return 1816.0000003 discounted reward 13.2728243\n",
      "Episode 9 return 1776.0000003 discounted reward 8.7690083\n",
      "Episode 10 return 1668.0000003 discounted reward 12.9908573\n",
      "Episode 11 return 1838.0000003 discounted reward 13.5494533\n",
      "Episode 12 return 2064.0000003 discounted reward 13.5653653\n",
      "Episode 13 return 1780.0000003 discounted reward 12.8955713\n",
      "Episode 14 return 1792.0000003 discounted reward 15.7660853\n",
      "Episode 15 return 1958.0000003 discounted reward 22.8282343\n",
      "Episode 16 return 1884.0000003 discounted reward 12.1260353\n",
      "Episode 17 return 2186.0000003 discounted reward 13.0353463\n",
      "Episode 18 return 1910.0000003 discounted reward 10.4668693\n",
      "Episode 19 return 1778.0000003 discounted reward 18.9334473\n",
      "Episode 20 return 1834.0000003 discounted reward 11.8912373\n",
      "Episode 21 return 1862.0000003 discounted reward 13.0604943\n",
      "Episode 22 return 1790.0000003 discounted reward 8.1089763\n",
      "Episode 23 return 1886.0000003 discounted reward 9.6480253\n",
      "Episode 24 return 2166.0000003 discounted reward 17.2353083\n",
      "Episode 25 return 1830.0000003 discounted reward 35.4908513\n",
      "Episode 26 return 1954.0000003 discounted reward 12.8998413\n",
      "Episode 27 return 2376.0000003 discounted reward 30.5601653\n",
      "Episode 28 return 1792.0000003 discounted reward 21.0748733\n",
      "Episode 29 return 1658.0000003 discounted reward 15.6027313\n",
      "Episode 30 return 1700.0000003 discounted reward 32.1732183\n",
      "Episode 31 return 2018.0000003 discounted reward 19.2075363\n",
      "Episode 32 return 1766.0000003 discounted reward 16.1250093\n",
      "Episode 33 return 1994.0000003 discounted reward 13.9985073\n",
      "Episode 34 return 2188.0000003 discounted reward 24.8884973\n",
      "Episode 35 return 1474.0000003 discounted reward 14.1844533\n",
      "Episode 36 return 1800.0000003 discounted reward 25.5776143\n",
      "Episode 37 return 2040.0000003 discounted reward 9.0786143\n",
      "Episode 38 return 1840.0000003 discounted reward 13.3357343\n",
      "Episode 39 return 1790.0000003 discounted reward 19.0832653\n",
      "Episode 40 return 1650.0000003 discounted reward 5.9946073\n",
      "Episode 41 return 1844.0000003 discounted reward 10.3056053\n",
      "Episode 42 return 1556.0000003 discounted reward 9.8518733\n",
      "Episode 43 return 1708.0000003 discounted reward 10.4028923\n",
      "Episode 44 return 2008.0000003 discounted reward 10.2007163\n",
      "Episode 45 return 2006.0000003 discounted reward 9.3592803\n",
      "Episode 46 return 1956.0000003 discounted reward 9.8737893\n",
      "Episode 47 return 2082.0000003 discounted reward 12.5368343\n",
      "Episode 48 return 1964.0000003 discounted reward 12.9092423\n",
      "Episode 49 return 1824.0000003 discounted reward 24.0369053\n",
      "Episode 50 return 1620.0000003 discounted reward 8.9834353\n",
      "Episode 51 return 1962.0000003 discounted reward 17.7516303\n",
      "Episode 52 return 1770.0000003 discounted reward 34.3071283\n",
      "Episode 53 return 2224.0000003 discounted reward 18.6090653\n",
      "Episode 54 return 1900.0000003 discounted reward 9.0376003\n",
      "Episode 55 return 1994.0000003 discounted reward 12.3669713\n",
      "Episode 56 return 1784.0000003 discounted reward 9.1753343\n",
      "Episode 57 return 1870.0000003 discounted reward 16.7062613\n",
      "Episode 58 return 1644.0000003 discounted reward 13.9022693\n",
      "Episode 59 return 1810.0000003 discounted reward 11.9576363\n",
      "Episode 60 return 1994.0000003 discounted reward 17.1785973\n",
      "Episode 61 return 1838.0000003 discounted reward 8.3738583\n",
      "Episode 62 return 1926.0000003 discounted reward 12.9250063\n",
      "Episode 63 return 1718.0000003 discounted reward 9.2878113\n",
      "Episode 64 return 2016.0000003 discounted reward 31.0171313\n",
      "Episode 65 return 1672.0000003 discounted reward 14.9286553\n",
      "Episode 66 return 1932.0000003 discounted reward 13.1109543\n",
      "Episode 67 return 1592.0000003 discounted reward 12.4290643\n",
      "Episode 68 return 1992.0000003 discounted reward 13.7289783\n",
      "Episode 69 return 1906.0000003 discounted reward 10.5131773\n",
      "Episode 70 return 1860.0000003 discounted reward 21.5112253\n",
      "Episode 71 return 1820.0000003 discounted reward 14.0866993\n",
      "Episode 72 return 1938.0000003 discounted reward 8.1595243\n",
      "Episode 73 return 1802.0000003 discounted reward 12.7131773\n",
      "Episode 74 return 1654.0000003 discounted reward 16.9571523\n",
      "Episode 75 return 1994.0000003 discounted reward 16.2875273\n",
      "Episode 76 return 1758.0000003 discounted reward 5.7214963\n",
      "Episode 77 return 1734.0000003 discounted reward 8.6045753\n",
      "Episode 78 return 1708.0000003 discounted reward 21.8400783\n",
      "Episode 79 return 1750.0000003 discounted reward 7.1118533\n",
      "Episode 80 return 1774.0000003 discounted reward 7.9902113\n",
      "Episode 81 return 1870.0000003 discounted reward 13.4927153\n",
      "Episode 82 return 2072.0000003 discounted reward 16.5481103\n",
      "Episode 83 return 2064.0000003 discounted reward 19.5249523\n",
      "Episode 84 return 1710.0000003 discounted reward 11.3131133\n",
      "Episode 85 return 1794.0000003 discounted reward 12.7053573\n",
      "Episode 86 return 1868.0000003 discounted reward 26.9566403\n",
      "Episode 87 return 1876.0000003 discounted reward 14.0356683\n",
      "Episode 88 return 1778.0000003 discounted reward 12.5623373\n",
      "Episode 89 return 1930.0000003 discounted reward 23.2774333\n",
      "Episode 90 return 1790.0000003 discounted reward 8.3335303\n",
      "Episode 91 return 1906.0000003 discounted reward 17.0088353\n",
      "Episode 92 return 2026.0000003 discounted reward 15.1515013\n",
      "Episode 93 return 1578.0000003 discounted reward 9.7477833\n",
      "Episode 94 return 1748.0000003 discounted reward 14.6215783\n",
      "Episode 95 return 1918.0000003 discounted reward 13.7416333\n",
      "Episode 96 return 2044.0000003 discounted reward 7.6748913\n",
      "Episode 97 return 1720.0000003 discounted reward 13.4881583\n",
      "Episode 98 return 1930.0000003 discounted reward 11.1876743\n",
      "Episode 99 return 1974.0000003 discounted reward 14.2573443\n",
      "Episode 100 return 1858.0000003 discounted reward 31.3815483\n",
      "Episode 101 return 1792.0000003 discounted reward 11.9396563\n",
      "Episode 102 return 1848.0000003 discounted reward 20.3423673\n",
      "Episode 103 return 1794.0000003 discounted reward 29.4863743\n",
      "Episode 104 return 2004.0000003 discounted reward 13.4757533\n",
      "Episode 105 return 1950.0000003 discounted reward 26.7962933\n",
      "Episode 106 return 1926.0000003 discounted reward 15.0463513\n",
      "Episode 107 return 1746.0000003 discounted reward 15.6723293\n",
      "Episode 108 return 1474.0000003 discounted reward 14.0535573\n",
      "Episode 109 return 2088.0000003 discounted reward 15.9141313\n",
      "Episode 110 return 1672.0000003 discounted reward 13.7714113\n",
      "Episode 111 return 1886.0000003 discounted reward 12.2015073\n",
      "Episode 112 return 1718.0000003 discounted reward 11.8327673\n",
      "Episode 113 return 1648.0000003 discounted reward 11.3873083\n",
      "Episode 114 return 1852.0000003 discounted reward 13.4657153\n",
      "Episode 115 return 1698.0000003 discounted reward 16.9679823\n",
      "Episode 116 return 1856.0000003 discounted reward 31.1572223\n",
      "Episode 117 return 2096.0000003 discounted reward 15.5128113\n",
      "Episode 118 return 2108.0000003 discounted reward 9.3184863\n",
      "Episode 119 return 1614.0000003 discounted reward 30.9133283\n",
      "Episode 120 return 1998.0000003 discounted reward 12.5314063\n",
      "Episode 121 return 1766.0000003 discounted reward 8.8351623\n",
      "Episode 122 return 1726.0000003 discounted reward 8.7430983\n",
      "Episode 123 return 2080.0000003 discounted reward 23.9487413\n",
      "Episode 124 return 1978.0000003 discounted reward 14.0229753\n",
      "Episode 125 return 2126.0000003 discounted reward 11.9318083\n",
      "Episode 126 return 1986.0000003 discounted reward 12.9870553\n",
      "Episode 127 return 1788.0000003 discounted reward 13.7704523\n",
      "Episode 128 return 1632.0000003 discounted reward 6.4234653\n",
      "Episode 129 return 1970.0000003 discounted reward 19.1491843\n",
      "Episode 130 return 1736.0000003 discounted reward 20.1744673\n",
      "Episode 131 return 1946.0000003 discounted reward 23.5412103\n",
      "Episode 132 return 1706.0000003 discounted reward 13.0139933\n",
      "Episode 133 return 1834.0000003 discounted reward 17.9411483\n",
      "Episode 134 return 1656.0000003 discounted reward 12.0553053\n",
      "Episode 135 return 1880.0000003 discounted reward 12.7496473\n",
      "Episode 136 return 2140.0000003 discounted reward 25.2187333\n",
      "Episode 137 return 1816.0000003 discounted reward 8.5458163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 1812.0000003 discounted reward 11.3481933\n",
      "Episode 139 return 1794.0000003 discounted reward 8.1444703\n",
      "Episode 140 return 2220.0000003 discounted reward 20.7823313\n",
      "Episode 141 return 1548.0000003 discounted reward 22.4362303\n",
      "Episode 142 return 1916.0000003 discounted reward 13.3935003\n",
      "Episode 143 return 1652.0000003 discounted reward 8.6088413\n",
      "Episode 144 return 1956.0000003 discounted reward 9.5957353\n",
      "Episode 145 return 1914.0000003 discounted reward 9.7891223\n",
      "Episode 146 return 1810.0000003 discounted reward 14.2324513\n",
      "Episode 147 return 1954.0000003 discounted reward 11.6108353\n",
      "Episode 148 return 1800.0000003 discounted reward 15.5099233\n",
      "Episode 149 return 1998.0000003 discounted reward 9.4545103\n",
      "Episode 150 return 1720.0000003 discounted reward 14.7760373\n",
      "Episode 151 return 1718.0000003 discounted reward 10.0530383\n",
      "Episode 152 return 1664.0000003 discounted reward 19.7354063\n",
      "Episode 153 return 1750.0000003 discounted reward 11.7021343\n",
      "Episode 154 return 1548.0000003 discounted reward 12.5788393\n",
      "Episode 155 return 1952.0000003 discounted reward 14.8173823\n",
      "Episode 156 return 2106.0000003 discounted reward 12.1839623\n",
      "Episode 157 return 1942.0000003 discounted reward 8.5830623\n",
      "Episode 158 return 2012.0000003 discounted reward 39.0076283\n",
      "Episode 159 return 1714.0000003 discounted reward 7.3904243\n",
      "Episode 160 return 1826.0000003 discounted reward 7.7301783\n",
      "Episode 161 return 1838.0000003 discounted reward 9.8560023\n",
      "Episode 162 return 2164.0000003 discounted reward 22.5502743\n",
      "Episode 163 return 1924.0000003 discounted reward 14.6629963\n",
      "Episode 164 return 1796.0000003 discounted reward 22.9066973\n",
      "Episode 165 return 1972.0000003 discounted reward 16.1816253\n",
      "Episode 166 return 1924.0000003 discounted reward 11.1380153\n",
      "Episode 167 return 1844.0000003 discounted reward 12.9208943\n",
      "Episode 168 return 2034.0000003 discounted reward 9.1730113\n",
      "Episode 169 return 2034.0000003 discounted reward 12.1866023\n",
      "Episode 170 return 2030.0000003 discounted reward 15.2208673\n",
      "Episode 171 return 1840.0000003 discounted reward 13.6865433\n",
      "Episode 172 return 1692.0000003 discounted reward 21.8481233\n",
      "Episode 173 return 1900.0000003 discounted reward 23.0152423\n",
      "Episode 174 return 1546.0000003 discounted reward 9.8465933\n",
      "Episode 175 return 1976.0000003 discounted reward 19.2651343\n",
      "Episode 176 return 2068.0000003 discounted reward 15.9608553\n",
      "Episode 177 return 1522.0000003 discounted reward 9.5025003\n",
      "Episode 178 return 1892.0000003 discounted reward 15.4322773\n",
      "Episode 179 return 1770.0000003 discounted reward 18.3184943\n",
      "Episode 180 return 2092.0000003 discounted reward 16.9212763\n",
      "Episode 181 return 1932.0000003 discounted reward 13.5013233\n",
      "Episode 182 return 1818.0000003 discounted reward 10.8949763\n",
      "Episode 183 return 1974.0000003 discounted reward 11.8800013\n",
      "Episode 184 return 1590.0000003 discounted reward 9.0050063\n",
      "Episode 185 return 1760.0000003 discounted reward 34.1222583\n",
      "Episode 186 return 1602.0000003 discounted reward 7.6973513\n",
      "Episode 187 return 1934.0000003 discounted reward 14.6909093\n",
      "Episode 188 return 1758.0000003 discounted reward 24.4974793\n",
      "Episode 189 return 1696.0000003 discounted reward 8.7613493\n",
      "Episode 190 return 1716.0000003 discounted reward 12.1588883\n",
      "Episode 191 return 1810.0000003 discounted reward 7.3696173\n",
      "Episode 192 return 1772.0000003 discounted reward 13.4315143\n",
      "Episode 193 return 1860.0000003 discounted reward 13.5461373\n",
      "Episode 194 return 1812.0000003 discounted reward 8.1617003\n",
      "Episode 195 return 1892.0000003 discounted reward 35.4356043\n",
      "Episode 196 return 1774.0000003 discounted reward 13.2049133\n",
      "Episode 197 return 2050.0000003 discounted reward 14.5051923\n",
      "Episode 198 return 1888.0000003 discounted reward 11.9115003\n",
      "Episode 199 return 1892.0000003 discounted reward 12.6335253\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (online) + online human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1906.0000003 discounted reward 12.2633733\n",
      "Episode 1 return 2192.0000003 discounted reward 12.9228853\n",
      "Episode 2 return 1750.0000003 discounted reward 24.7576773\n",
      "Episode 3 return 1658.0000003 discounted reward 7.4807083\n",
      "Episode 4 return 1864.0000003 discounted reward 7.5849263\n",
      "Episode 5 return 1874.0000003 discounted reward 19.5005083\n",
      "Episode 6 return 2058.0000003 discounted reward 12.7689953\n",
      "Episode 7 return 1810.0000003 discounted reward 13.4749363\n",
      "Episode 8 return 1836.0000003 discounted reward 25.0055803\n",
      "Episode 9 return 1838.0000003 discounted reward 14.5670813\n",
      "Episode 10 return 1966.0000003 discounted reward 11.5246503\n",
      "Episode 11 return 1742.0000003 discounted reward 10.3355293\n",
      "Episode 12 return 1672.0000003 discounted reward 13.7137913\n",
      "Episode 13 return 1854.0000003 discounted reward 11.4427023\n",
      "Episode 14 return 1798.0000003 discounted reward 12.3605373\n",
      "Episode 15 return 1758.0000003 discounted reward 8.5150763\n",
      "Episode 16 return 1902.0000003 discounted reward 28.2325043\n",
      "Episode 17 return 1778.0000003 discounted reward 8.0886983\n",
      "Episode 18 return 1968.0000003 discounted reward 13.4784473\n",
      "Episode 19 return 1910.0000003 discounted reward 11.5727903\n",
      "Episode 20 return 1706.0000003 discounted reward 7.9630923\n",
      "Episode 21 return 1538.0000003 discounted reward 10.3095783\n",
      "Episode 22 return 1646.0000003 discounted reward 7.9741283\n",
      "Episode 23 return 1532.0000003 discounted reward 9.4833923\n",
      "Episode 24 return 1744.0000003 discounted reward 8.3700263\n",
      "Episode 25 return 1766.0000003 discounted reward 9.0814363\n",
      "Episode 26 return 1898.0000003 discounted reward 17.3510953\n",
      "Episode 27 return 1804.0000003 discounted reward 9.4230573\n",
      "Episode 28 return 1690.0000003 discounted reward 11.5235863\n",
      "Episode 29 return 1826.0000003 discounted reward 9.2500763\n",
      "Episode 30 return 1788.0000003 discounted reward 13.1869043\n",
      "Episode 31 return 1718.0000003 discounted reward 7.0664813\n",
      "Episode 32 return 1784.0000003 discounted reward 13.9000143\n",
      "Episode 33 return 2144.0000003 discounted reward 6.6384043\n",
      "Episode 34 return 1940.0000003 discounted reward 9.5729133\n",
      "Episode 35 return 1966.0000003 discounted reward 12.9112323\n",
      "Episode 36 return 1892.0000003 discounted reward 14.5437793\n",
      "Episode 37 return 1798.0000003 discounted reward 10.2240393\n",
      "Episode 38 return 1954.0000003 discounted reward 9.1098633\n",
      "Episode 39 return 2058.0000003 discounted reward 12.7567143\n",
      "Episode 40 return 1888.0000003 discounted reward 19.8791643\n",
      "Episode 41 return 1852.0000003 discounted reward 6.0627843\n",
      "Episode 42 return 1976.0000003 discounted reward 22.2672573\n",
      "Episode 43 return 1504.0000003 discounted reward 16.7299833\n",
      "Episode 44 return 1768.0000003 discounted reward 29.3639183\n",
      "Episode 45 return 1794.0000003 discounted reward 11.7861483\n",
      "Episode 46 return 1884.0000003 discounted reward 12.2159263\n",
      "Episode 47 return 1812.0000003 discounted reward 12.2801723\n",
      "Episode 48 return 1876.0000003 discounted reward 10.3500653\n",
      "Episode 49 return 1946.0000003 discounted reward 10.4238963\n",
      "Episode 50 return 1786.0000003 discounted reward 14.8846863\n",
      "Episode 51 return 2112.0000003 discounted reward 19.0945463\n",
      "Episode 52 return 1614.0000003 discounted reward 14.1730343\n",
      "Episode 53 return 2048.0000003 discounted reward 21.7856733\n",
      "Episode 54 return 1786.0000003 discounted reward 7.6221553\n",
      "Episode 55 return 2132.0000003 discounted reward 9.3018143\n",
      "Episode 56 return 2004.0000003 discounted reward 17.2112783\n",
      "Episode 57 return 1892.0000003 discounted reward 8.1458833\n",
      "Episode 58 return 1634.0000003 discounted reward 8.7092983\n",
      "Episode 59 return 1780.0000003 discounted reward 10.1287523\n",
      "Episode 60 return 1704.0000003 discounted reward 21.8336343\n",
      "Episode 61 return 1962.0000003 discounted reward 33.9698703\n",
      "Episode 62 return 2128.0000003 discounted reward 20.5343793\n",
      "Episode 63 return 1786.0000003 discounted reward 33.2162243\n",
      "Episode 64 return 1810.0000003 discounted reward 9.7453073\n",
      "Episode 65 return 1894.0000003 discounted reward 45.4962693\n",
      "Episode 66 return 1832.0000003 discounted reward 8.6778313\n",
      "Episode 67 return 1900.0000003 discounted reward 20.6288783\n",
      "Episode 68 return 1832.0000003 discounted reward 28.7617313\n",
      "Episode 69 return 1792.0000003 discounted reward 14.3425493\n",
      "Episode 70 return 1648.0000003 discounted reward 17.7090133\n",
      "Episode 71 return 1910.0000003 discounted reward 29.9708013\n",
      "Episode 72 return 1924.0000003 discounted reward 6.1641163\n",
      "Episode 73 return 1768.0000003 discounted reward 9.1998323\n",
      "Episode 74 return 1924.0000003 discounted reward 18.9219643\n",
      "Episode 75 return 1900.0000003 discounted reward 18.4699553\n",
      "Episode 76 return 1712.0000003 discounted reward 13.2356513\n",
      "Episode 77 return 2056.0000003 discounted reward 16.5999143\n",
      "Episode 78 return 2022.0000003 discounted reward 16.5923853\n",
      "Episode 79 return 2066.0000003 discounted reward 23.1323083\n",
      "Episode 80 return 1704.0000003 discounted reward 13.5907213\n",
      "Episode 81 return 1876.0000003 discounted reward 23.1070493\n",
      "Episode 82 return 1910.0000003 discounted reward 9.8103493\n",
      "Episode 83 return 2072.0000003 discounted reward 34.4725603\n",
      "Episode 84 return 1782.0000003 discounted reward 11.2592083\n",
      "Episode 85 return 2132.0000003 discounted reward 14.0666873\n",
      "Episode 86 return 1518.0000003 discounted reward 16.1901643\n",
      "Episode 87 return 1926.0000003 discounted reward 11.8430283\n",
      "Episode 88 return 1832.0000003 discounted reward 19.0147893\n",
      "Episode 89 return 1694.0000003 discounted reward 16.7623343\n",
      "Episode 90 return 1830.0000003 discounted reward 7.3673353\n",
      "Episode 91 return 1566.0000003 discounted reward 8.3786543\n",
      "Episode 92 return 1858.0000003 discounted reward 28.1052473\n",
      "Episode 93 return 2056.0000003 discounted reward 13.5532893\n",
      "Episode 94 return 1728.0000003 discounted reward 9.6111803\n",
      "Episode 95 return 1730.0000003 discounted reward 14.0901593\n",
      "Episode 96 return 1866.0000003 discounted reward 5.3426913\n",
      "Episode 97 return 1522.0000003 discounted reward 12.0893893\n",
      "Episode 98 return 1620.0000003 discounted reward 22.5094693\n",
      "Episode 99 return 1974.0000003 discounted reward 22.2965993\n",
      "Episode 100 return 1544.0000003 discounted reward 10.7945333\n",
      "Episode 101 return 1536.0000003 discounted reward 10.0481253\n",
      "Episode 102 return 1550.0000003 discounted reward 17.8470123\n",
      "Episode 103 return 2002.0000003 discounted reward 9.8583453\n",
      "Episode 104 return 2036.0000003 discounted reward 38.8475133\n",
      "Episode 105 return 1928.0000003 discounted reward 9.1952873\n",
      "Episode 106 return 1918.0000003 discounted reward 28.7613543\n",
      "Episode 107 return 1578.0000003 discounted reward 12.2180773\n",
      "Episode 108 return 1626.0000003 discounted reward 11.0585153\n",
      "Episode 109 return 1868.0000003 discounted reward 8.9301413\n",
      "Episode 110 return 2064.0000003 discounted reward 18.7273553\n",
      "Episode 111 return 1600.0000003 discounted reward 8.9297973\n",
      "Episode 112 return 1890.0000003 discounted reward 18.9354453\n",
      "Episode 113 return 2102.0000003 discounted reward 8.0281483\n",
      "Episode 114 return 1662.0000003 discounted reward 17.4958153\n",
      "Episode 115 return 1842.0000003 discounted reward 11.3751913\n",
      "Episode 116 return 1740.0000003 discounted reward 14.9850723\n",
      "Episode 117 return 1808.0000003 discounted reward 8.4326003\n",
      "Episode 118 return 2024.0000003 discounted reward 8.3508803\n",
      "Episode 119 return 1722.0000003 discounted reward 8.8626043\n",
      "Episode 120 return 1582.0000003 discounted reward 15.5159343\n",
      "Episode 121 return 2134.0000003 discounted reward 53.8468963\n",
      "Episode 122 return 1754.0000003 discounted reward 11.5523093\n",
      "Episode 123 return 2032.0000003 discounted reward 13.1216253\n",
      "Episode 124 return 1892.0000003 discounted reward 14.1965983\n",
      "Episode 125 return 1822.0000003 discounted reward 19.8626383\n",
      "Episode 126 return 2290.0000003 discounted reward 10.7229873\n",
      "Episode 127 return 1718.0000003 discounted reward 7.6642993\n",
      "Episode 128 return 2046.0000003 discounted reward 13.7031753\n",
      "Episode 129 return 1980.0000003 discounted reward 9.6859713\n",
      "Episode 130 return 2026.0000003 discounted reward 12.7551303\n",
      "Episode 131 return 1890.0000003 discounted reward 12.9216793\n",
      "Episode 132 return 1948.0000003 discounted reward 17.8037373\n",
      "Episode 133 return 1916.0000003 discounted reward 17.5166213\n",
      "Episode 134 return 1852.0000003 discounted reward 7.3513273\n",
      "Episode 135 return 1846.0000003 discounted reward 25.5587053\n",
      "Episode 136 return 1796.0000003 discounted reward 19.1155623\n",
      "Episode 137 return 2062.0000003 discounted reward 14.9694423\n",
      "Episode 138 return 1708.0000003 discounted reward 9.1916613\n",
      "Episode 139 return 1910.0000003 discounted reward 8.2925503\n",
      "Episode 140 return 1694.0000003 discounted reward 14.1292483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 141 return 1764.0000003 discounted reward 15.1960123\n",
      "Episode 142 return 2210.0000003 discounted reward 19.1975293\n",
      "Episode 143 return 1932.0000003 discounted reward 7.2800243\n",
      "Episode 144 return 1736.0000003 discounted reward 13.9374083\n",
      "Episode 145 return 2040.0000003 discounted reward 10.1708773\n",
      "Episode 146 return 1754.0000003 discounted reward 17.2994073\n",
      "Episode 147 return 1718.0000003 discounted reward 26.1705923\n",
      "Episode 148 return 1962.0000003 discounted reward 14.4382453\n",
      "Episode 149 return 1630.0000003 discounted reward 10.9506553\n",
      "Episode 150 return 1848.0000003 discounted reward 9.4881003\n",
      "Episode 151 return 2036.0000003 discounted reward 12.2491993\n",
      "Episode 152 return 1748.0000003 discounted reward 15.8822463\n",
      "Episode 153 return 2022.0000003 discounted reward 26.4821923\n",
      "Episode 154 return 1698.0000003 discounted reward 12.1306833\n",
      "Episode 155 return 1966.0000003 discounted reward 36.1853913\n",
      "Episode 156 return 1912.0000003 discounted reward 9.4485943\n",
      "Episode 157 return 1536.0000003 discounted reward 7.0214223\n",
      "Episode 158 return 1932.0000003 discounted reward 11.2303363\n",
      "Episode 159 return 2092.0000003 discounted reward 10.5956603\n",
      "Episode 160 return 2150.0000003 discounted reward 12.9879663\n",
      "Episode 161 return 1888.0000003 discounted reward 9.9096163\n",
      "Episode 162 return 1808.0000003 discounted reward 12.1429163\n",
      "Episode 163 return 2158.0000003 discounted reward 13.5777513\n",
      "Episode 164 return 1972.0000003 discounted reward 8.3423663\n",
      "Episode 165 return 1948.0000003 discounted reward 7.3681883\n",
      "Episode 166 return 1988.0000003 discounted reward 28.6069013\n",
      "Episode 167 return 1948.0000003 discounted reward 8.4111183\n",
      "Episode 168 return 2012.0000003 discounted reward 19.2680313\n",
      "Episode 169 return 2078.0000003 discounted reward 11.3412563\n",
      "Episode 170 return 1742.0000003 discounted reward 10.9521213\n",
      "Episode 171 return 1670.0000003 discounted reward 15.6798113\n",
      "Episode 172 return 2104.0000003 discounted reward 6.9955563\n",
      "Episode 173 return 1846.0000003 discounted reward 8.8879213\n",
      "Episode 174 return 1694.0000003 discounted reward 9.9891723\n",
      "Episode 175 return 2188.0000003 discounted reward 18.7095203\n",
      "Episode 176 return 1914.0000003 discounted reward 15.2973703\n",
      "Episode 177 return 1976.0000003 discounted reward 9.2049903\n",
      "Episode 178 return 1878.0000003 discounted reward 17.6770943\n",
      "Episode 179 return 1906.0000003 discounted reward 11.9753993\n",
      "Episode 180 return 1930.0000003 discounted reward 11.1077073\n",
      "Episode 181 return 1668.0000003 discounted reward 11.7077133\n",
      "Episode 182 return 1736.0000003 discounted reward 25.7454813\n",
      "Episode 183 return 1496.0000003 discounted reward 12.2182723\n",
      "Episode 184 return 1990.0000003 discounted reward 13.5808513\n",
      "Episode 185 return 1736.0000003 discounted reward 12.7874873\n",
      "Episode 186 return 1816.0000003 discounted reward 12.6131663\n",
      "Episode 187 return 1742.0000003 discounted reward 22.6811603\n",
      "Episode 188 return 1584.0000003 discounted reward 13.6808933\n",
      "Episode 189 return 2084.0000003 discounted reward 9.0526903\n",
      "Episode 190 return 2104.0000003 discounted reward 55.5307743\n",
      "Episode 191 return 1664.0000003 discounted reward 22.0592713\n",
      "Episode 192 return 1796.0000003 discounted reward 7.9590353\n",
      "Episode 193 return 1724.0000003 discounted reward 7.6376563\n",
      "Episode 194 return 1874.0000003 discounted reward 9.2454383\n",
      "Episode 195 return 1624.0000003 discounted reward 11.9996253\n",
      "Episode 196 return 2220.0000003 discounted reward 17.3352493\n",
      "Episode 197 return 2080.0000003 discounted reward 11.1930843\n",
      "Episode 198 return 1754.0000003 discounted reward 9.6506193\n",
      "Episode 199 return 1918.0000003 discounted reward 16.4151523\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning-online-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "human_recommendation = dict([(0,0),(1,0),(2,0),(3,0),(4,0)])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            \n",
    "            #--------------- Human in the loop --------------- #\n",
    "            if human_recommendation[observation] != a: \n",
    "                Q[observation][a] -= 1\n",
    "            else:\n",
    "                Q[observation][a] += 1\n",
    "            #------------------------------------------------- #\n",
    "            \n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning (online) + offline human interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 return 1454.0000003 discounted reward 11.1680643\n",
      "Episode 1 return 1686.0000003 discounted reward 22.0647653\n",
      "Episode 2 return 1998.0000003 discounted reward 16.1563243\n",
      "Episode 3 return 1684.0000003 discounted reward 10.0673613\n",
      "Episode 4 return 1716.0000003 discounted reward 7.4343733\n",
      "Episode 5 return 1782.0000003 discounted reward 22.2644223\n",
      "Episode 6 return 1920.0000003 discounted reward 21.1456623\n",
      "Episode 7 return 2094.0000003 discounted reward 13.8939823\n",
      "Episode 8 return 2122.0000003 discounted reward 22.9519753\n",
      "Episode 9 return 1550.0000003 discounted reward 7.0853743\n",
      "Episode 10 return 1848.0000003 discounted reward 24.8896833\n",
      "Episode 11 return 1862.0000003 discounted reward 15.5312153\n",
      "Episode 12 return 1486.0000003 discounted reward 13.9285403\n",
      "Episode 13 return 1756.0000003 discounted reward 29.1171583\n",
      "Episode 14 return 2044.0000003 discounted reward 13.3825243\n",
      "Episode 15 return 1994.0000003 discounted reward 12.3265723\n",
      "Episode 16 return 1772.0000003 discounted reward 10.2070053\n",
      "Episode 17 return 1982.0000003 discounted reward 10.3839893\n",
      "Episode 18 return 1620.0000003 discounted reward 10.9277223\n",
      "Episode 19 return 1562.0000003 discounted reward 21.3664953\n",
      "Episode 20 return 1980.0000003 discounted reward 11.6064653\n",
      "Episode 21 return 1958.0000003 discounted reward 15.3691563\n",
      "Episode 22 return 1684.0000003 discounted reward 12.1876723\n",
      "Episode 23 return 1684.0000003 discounted reward 9.6054143\n",
      "Episode 24 return 1754.0000003 discounted reward 7.9008693\n",
      "Episode 25 return 1782.0000003 discounted reward 10.4140713\n",
      "Episode 26 return 1680.0000003 discounted reward 7.6164733\n",
      "Episode 27 return 1824.0000003 discounted reward 12.9750933\n",
      "Episode 28 return 1674.0000003 discounted reward 12.8436913\n",
      "Episode 29 return 1882.0000003 discounted reward 7.1918043\n",
      "Episode 30 return 2196.0000003 discounted reward 10.8126933\n",
      "Episode 31 return 1980.0000003 discounted reward 12.6397983\n",
      "Episode 32 return 1804.0000003 discounted reward 7.4715263\n",
      "Episode 33 return 1804.0000003 discounted reward 16.0643383\n",
      "Episode 34 return 1986.0000003 discounted reward 10.0252893\n",
      "Episode 35 return 1896.0000003 discounted reward 13.6010253\n",
      "Episode 36 return 1668.0000003 discounted reward 11.9907873\n",
      "Episode 37 return 1926.0000003 discounted reward 26.5473083\n",
      "Episode 38 return 1806.0000003 discounted reward 10.3128033\n",
      "Episode 39 return 2084.0000003 discounted reward 14.4074193\n",
      "Episode 40 return 1680.0000003 discounted reward 14.5113403\n",
      "Episode 41 return 1562.0000003 discounted reward 9.6733443\n",
      "Episode 42 return 1980.0000003 discounted reward 42.5581893\n",
      "Episode 43 return 2244.0000003 discounted reward 10.5541393\n",
      "Episode 44 return 1718.0000003 discounted reward 14.0743853\n",
      "Episode 45 return 1878.0000003 discounted reward 10.4575453\n",
      "Episode 46 return 1882.0000003 discounted reward 11.7382843\n",
      "Episode 47 return 1892.0000003 discounted reward 15.6594343\n",
      "Episode 48 return 2058.0000003 discounted reward 9.8173783\n",
      "Episode 49 return 1786.0000003 discounted reward 18.2413373\n",
      "Episode 50 return 1712.0000003 discounted reward 11.8356963\n",
      "Episode 51 return 1978.0000003 discounted reward 12.9948133\n",
      "Episode 52 return 1962.0000003 discounted reward 10.0714683\n",
      "Episode 53 return 1890.0000003 discounted reward 20.1493393\n",
      "Episode 54 return 1630.0000003 discounted reward 13.6318903\n",
      "Episode 55 return 1856.0000003 discounted reward 18.7637993\n",
      "Episode 56 return 1804.0000003 discounted reward 12.0566823\n",
      "Episode 57 return 1826.0000003 discounted reward 11.2255453\n",
      "Episode 58 return 1760.0000003 discounted reward 8.4172533\n",
      "Episode 59 return 2138.0000003 discounted reward 20.9531283\n",
      "Episode 60 return 1924.0000003 discounted reward 10.8982713\n",
      "Episode 61 return 1890.0000003 discounted reward 20.3473353\n",
      "Episode 62 return 1864.0000003 discounted reward 14.3598243\n",
      "Episode 63 return 1874.0000003 discounted reward 6.9722093\n",
      "Episode 64 return 1880.0000003 discounted reward 12.7990343\n",
      "Episode 65 return 1742.0000003 discounted reward 14.3367783\n",
      "Episode 66 return 1840.0000003 discounted reward 10.6662423\n",
      "Episode 67 return 1740.0000003 discounted reward 7.1939803\n",
      "Episode 68 return 2254.0000003 discounted reward 52.3578353\n",
      "Episode 69 return 1916.0000003 discounted reward 10.8082223\n",
      "Episode 70 return 1910.0000003 discounted reward 7.6850803\n",
      "Episode 71 return 1588.0000003 discounted reward 11.6618973\n",
      "Episode 72 return 1688.0000003 discounted reward 8.8495963\n",
      "Episode 73 return 1876.0000003 discounted reward 13.8212633\n",
      "Episode 74 return 1798.0000003 discounted reward 18.7006843\n",
      "Episode 75 return 1560.0000003 discounted reward 13.3836823\n",
      "Episode 76 return 1618.0000003 discounted reward 7.8085933\n",
      "Episode 77 return 1656.0000003 discounted reward 17.6712183\n",
      "Episode 78 return 1670.0000003 discounted reward 8.9873913\n",
      "Episode 79 return 1724.0000003 discounted reward 15.1293483\n",
      "Episode 80 return 1730.0000003 discounted reward 10.0769903\n",
      "Episode 81 return 1788.0000003 discounted reward 13.8261523\n",
      "Episode 82 return 1712.0000003 discounted reward 12.8987483\n",
      "Episode 83 return 1766.0000003 discounted reward 12.0089243\n",
      "Episode 84 return 1846.0000003 discounted reward 13.4200243\n",
      "Episode 85 return 1892.0000003 discounted reward 19.0131863\n",
      "Episode 86 return 1792.0000003 discounted reward 12.4242743\n",
      "Episode 87 return 1904.0000003 discounted reward 19.3419613\n",
      "Episode 88 return 1522.0000003 discounted reward 8.5186193\n",
      "Episode 89 return 1956.0000003 discounted reward 19.0844593\n",
      "Episode 90 return 2010.0000003 discounted reward 8.1843853\n",
      "Episode 91 return 1728.0000003 discounted reward 10.5830193\n",
      "Episode 92 return 1804.0000003 discounted reward 12.5364283\n",
      "Episode 93 return 1776.0000003 discounted reward 12.2527473\n",
      "Episode 94 return 2010.0000003 discounted reward 9.9335173\n",
      "Episode 95 return 1950.0000003 discounted reward 27.2731313\n",
      "Episode 96 return 1838.0000003 discounted reward 18.7651643\n",
      "Episode 97 return 1908.0000003 discounted reward 10.0841113\n",
      "Episode 98 return 1984.0000003 discounted reward 12.8662713\n",
      "Episode 99 return 2004.0000003 discounted reward 8.1168513\n",
      "Episode 100 return 2226.0000003 discounted reward 18.2097653\n",
      "Episode 101 return 1688.0000003 discounted reward 9.9983503\n",
      "Episode 102 return 1648.0000003 discounted reward 9.7370983\n",
      "Episode 103 return 1974.0000003 discounted reward 40.4125473\n",
      "Episode 104 return 2098.0000003 discounted reward 33.9786833\n",
      "Episode 105 return 1984.0000003 discounted reward 15.7614733\n",
      "Episode 106 return 1900.0000003 discounted reward 10.9479813\n",
      "Episode 107 return 1768.0000003 discounted reward 11.0926973\n",
      "Episode 108 return 1918.0000003 discounted reward 5.7867563\n",
      "Episode 109 return 1712.0000003 discounted reward 21.7137833\n",
      "Episode 110 return 1750.0000003 discounted reward 9.0792273\n",
      "Episode 111 return 1762.0000003 discounted reward 11.3954093\n",
      "Episode 112 return 1818.0000003 discounted reward 20.9033703\n",
      "Episode 113 return 1768.0000003 discounted reward 10.2130963\n",
      "Episode 114 return 1714.0000003 discounted reward 9.1781653\n",
      "Episode 115 return 2020.0000003 discounted reward 16.0806633\n",
      "Episode 116 return 1912.0000003 discounted reward 15.2457103\n",
      "Episode 117 return 1898.0000003 discounted reward 36.7978973\n",
      "Episode 118 return 1908.0000003 discounted reward 29.7307003\n",
      "Episode 119 return 1804.0000003 discounted reward 22.1738563\n",
      "Episode 120 return 1562.0000003 discounted reward 8.9326183\n",
      "Episode 121 return 1896.0000003 discounted reward 31.2193423\n",
      "Episode 122 return 1772.0000003 discounted reward 16.7075493\n",
      "Episode 123 return 1718.0000003 discounted reward 23.8685173\n",
      "Episode 124 return 1950.0000003 discounted reward 12.2981913\n",
      "Episode 125 return 1864.0000003 discounted reward 5.5986383\n",
      "Episode 126 return 1684.0000003 discounted reward 27.1587973\n",
      "Episode 127 return 1894.0000003 discounted reward 19.0790143\n",
      "Episode 128 return 1950.0000003 discounted reward 19.2011063\n",
      "Episode 129 return 1772.0000003 discounted reward 10.8751143\n",
      "Episode 130 return 2166.0000003 discounted reward 31.9603413\n",
      "Episode 131 return 1812.0000003 discounted reward 19.3885663\n",
      "Episode 132 return 1960.0000003 discounted reward 16.9652693\n",
      "Episode 133 return 1926.0000003 discounted reward 13.2532603\n",
      "Episode 134 return 1916.0000003 discounted reward 13.1277103\n",
      "Episode 135 return 1760.0000003 discounted reward 9.5598363\n",
      "Episode 136 return 1822.0000003 discounted reward 10.2985283\n",
      "Episode 137 return 1688.0000003 discounted reward 15.4396023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 138 return 1936.0000003 discounted reward 14.7488063\n",
      "Episode 139 return 1882.0000003 discounted reward 7.4128723\n",
      "Episode 140 return 1886.0000003 discounted reward 11.4244173\n",
      "Episode 141 return 1854.0000003 discounted reward 12.4375043\n",
      "Episode 142 return 1906.0000003 discounted reward 17.1917513\n",
      "Episode 143 return 1816.0000003 discounted reward 8.0876653\n",
      "Episode 144 return 1734.0000003 discounted reward 10.0271463\n",
      "Episode 145 return 1940.0000003 discounted reward 19.6891583\n",
      "Episode 146 return 2000.0000003 discounted reward 31.1867233\n",
      "Episode 147 return 1588.0000003 discounted reward 11.5051633\n",
      "Episode 148 return 1748.0000003 discounted reward 17.8314133\n",
      "Episode 149 return 1918.0000003 discounted reward 6.2882423\n",
      "Episode 150 return 1794.0000003 discounted reward 14.6163673\n",
      "Episode 151 return 1976.0000003 discounted reward 27.6193553\n",
      "Episode 152 return 2054.0000003 discounted reward 9.2033843\n",
      "Episode 153 return 1548.0000003 discounted reward 14.8948303\n",
      "Episode 154 return 1870.0000003 discounted reward 21.7439153\n",
      "Episode 155 return 1900.0000003 discounted reward 13.4204933\n",
      "Episode 156 return 1676.0000003 discounted reward 8.8441553\n",
      "Episode 157 return 1876.0000003 discounted reward 12.2555783\n",
      "Episode 158 return 1686.0000003 discounted reward 14.7413363\n",
      "Episode 159 return 1754.0000003 discounted reward 13.3903263\n",
      "Episode 160 return 2034.0000003 discounted reward 11.3388583\n",
      "Episode 161 return 2028.0000003 discounted reward 14.6472903\n",
      "Episode 162 return 1868.0000003 discounted reward 11.2423123\n",
      "Episode 163 return 2126.0000003 discounted reward 13.7497683\n",
      "Episode 164 return 1714.0000003 discounted reward 10.3017543\n",
      "Episode 165 return 1548.0000003 discounted reward 16.4871373\n",
      "Episode 166 return 1662.0000003 discounted reward 11.1039923\n",
      "Episode 167 return 1676.0000003 discounted reward 12.7691013\n",
      "Episode 168 return 1786.0000003 discounted reward 20.3094183\n",
      "Episode 169 return 1608.0000003 discounted reward 10.5236623\n",
      "Episode 170 return 2030.0000003 discounted reward 8.5416783\n",
      "Episode 171 return 1938.0000003 discounted reward 15.8370913\n",
      "Episode 172 return 1764.0000003 discounted reward 9.7595243\n",
      "Episode 173 return 1826.0000003 discounted reward 8.3662573\n",
      "Episode 174 return 1882.0000003 discounted reward 11.2538363\n",
      "Episode 175 return 1924.0000003 discounted reward 17.7467483\n",
      "Episode 176 return 1684.0000003 discounted reward 20.8330943\n",
      "Episode 177 return 1764.0000003 discounted reward 15.0645333\n",
      "Episode 178 return 1776.0000003 discounted reward 11.7337523\n",
      "Episode 179 return 1956.0000003 discounted reward 8.5935193\n",
      "Episode 180 return 2104.0000003 discounted reward 16.7776933\n",
      "Episode 181 return 1630.0000003 discounted reward 23.3548853\n",
      "Episode 182 return 1948.0000003 discounted reward 37.5477403\n",
      "Episode 183 return 1736.0000003 discounted reward 9.8269333\n",
      "Episode 184 return 2064.0000003 discounted reward 13.7318333\n",
      "Episode 185 return 1596.0000003 discounted reward 5.4289763\n",
      "Episode 186 return 1740.0000003 discounted reward 10.5148283\n",
      "Episode 187 return 1926.0000003 discounted reward 10.9858183\n",
      "Episode 188 return 1780.0000003 discounted reward 8.1218313\n",
      "Episode 189 return 1564.0000003 discounted reward 12.0308593\n",
      "Episode 190 return 1754.0000003 discounted reward 7.2718423\n",
      "Episode 191 return 1920.0000003 discounted reward 11.9536873\n",
      "Episode 192 return 1884.0000003 discounted reward 8.7846983\n",
      "Episode 193 return 1954.0000003 discounted reward 11.7078763\n",
      "Episode 194 return 1854.0000003 discounted reward 17.8254073\n",
      "Episode 195 return 1462.0000003 discounted reward 8.9919493\n",
      "Episode 196 return 2092.0000003 discounted reward 9.4479423\n",
      "Episode 197 return 2032.0000003 discounted reward 6.9334463\n",
      "Episode 198 return 1780.0000003 discounted reward 10.7152653\n",
      "Episode 199 return 1744.0000003 discounted reward 14.9790713\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "num_actions = 2\n",
    "\n",
    "file_name = \"log_files/NChain-q-learning-offline-human/\" + str(time.time()) + \".csv\"\n",
    "with open(file_name, 'w+') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\")\n",
    "    writer.writerow([\"r\", \"l\", \"t\"])\n",
    "\n",
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    def policy_fn(observation):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        best_action = np.argmax(Q[observation])\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "def q_learning(env, num_episodes, discount_factor=0.9, alpha=0.2, epsilon=0.5, max_steps = 1000):\n",
    "    Q = defaultdict(lambda: np.zeros(num_actions))\n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, num_actions)\n",
    "    env.reset()\n",
    "    start = time.time()\n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        discounted_reward = 0\n",
    "        total_reward = 0\n",
    "        for i in itertools.count():\n",
    "            a_prob = policy(observation)\n",
    "            a = np.random.choice([i for i in range(len(a_prob))], p = a_prob)\n",
    "            next_observation, reward, done, _ = env.step(a)\n",
    "            best_next_a = np.argmax(Q[next_observation])\n",
    "            Q[observation][a] += alpha * (reward + discount_factor * Q[next_observation][best_next_a] - Q[observation][a])\n",
    "            discounted_reward += (discount_factor**i)*reward\n",
    "            total_reward += reward\n",
    "            if done or i > max_steps:\n",
    "                print('Episode %d return %f3 discounted reward %f3' %(i_episode, total_reward, discounted_reward))\n",
    "                break\n",
    "            observation = next_observation\n",
    "            \n",
    "        # human modifies Q\n",
    "        Q[0][0] += 0.1\n",
    "        Q[1][0] += 0.1\n",
    "        Q[2][0] += 0.1\n",
    "        Q[3][0] += 0.1\n",
    "        Q[4][0] += 0.1\n",
    "        \n",
    "        runtime = time.time() - start\n",
    "        with open(file_name, 'a') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter=\",\")\n",
    "            writer.writerow((str(total_reward), str(i), str(runtime)))\n",
    "    return Q\n",
    "\n",
    "Q = q_learning(env, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
